<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>vcd.scl API documentation</title>
<meta name="description" content="VCD (Video Content Description) library v4.3.1 …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>vcd.scl</code></h1>
</header>
<section id="section-intro">
<p>VCD (Video Content Description) library v4.3.1</p>
<p>Project website: <a href="http://vcd.vicomtech.org">http://vcd.vicomtech.org</a></p>
<p>Copyright (C) 2021, Vicomtech (<a href="http://www.vicomtech.es/">http://www.vicomtech.es/</a>),
(Spain) all rights reserved.</p>
<p>VCD is a Python library to create and manage VCD content version 4.3.1.
VCD is distributed under MIT License. See LICENSE.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
VCD (Video Content Description) library v4.3.1

Project website: http://vcd.vicomtech.org

Copyright (C) 2021, Vicomtech (http://www.vicomtech.es/),
(Spain) all rights reserved.

VCD is a Python library to create and manage VCD content version 4.3.1.
VCD is distributed under MIT License. See LICENSE.

&#34;&#34;&#34;

import numpy as np
import warnings
import cv2 as cv
from collections import deque, namedtuple
import time

from numpy import float64

import vcd.utils as utils
import math

#TODO: Review SCL principles according to VCD 4.3.0 coordiante systems and transforms
from vcd.types import areaReference

&#39;&#39;&#39; ######################################################    
    Basic principles of SCL (Scene Configuration Library)
    ######################################################
    SCL provides some routines and functions, but it is also a guide to produce scenes coherently.
    Read carefully these principles, and see them in practice on the samples.

    SCL is based on common conventions. In some cases, SCL allows using different conventions, but eventually
    it enforces using specific conventions, such as &#34;right-hand&#34; coordinate systems, homogeneous coordinates, 
    left-multiplication of matrices, alias (vs alibi) rotation matrices, etc.

    NUMPY ARRAYS
    -----------------------------
    All geometric data is expressed as numpy n-dimensional arrays.    

    HOMOGENEOUS DATA
    -----------------------------
    All geometric data (points, lines) are expressed in homogeneous coordinates (columns)
    All matrices are also expressed in homogeneous coordinates.
    E.g. 3D points are column vectors 4x1
         camera calibration matrix (K) is 3x4 matrix, where last row is all zeros and 1.0
         all poses are expressed as 4x4 matrices
         rotation matrices are 3x3
         If not specified otherwise, all one-dimensional vectors are column vectors

    POSES AND COORDINATE SYSTEMS
    -----------------------------
    Each sensor has a &#34;static pose&#34; defined against the Local Coordinate System (LCS). In the case of
    vehicle set-ups, this LCS is a point at the ego-vehicle located at
    the middle of the rear axle, projected to the ground, being X-to-front, Y-to-left, Z-up
    as defined in the ISO8855. There are some other coordinates systems considered in SCL:

        - LCS : Local Coordinate System (e.g. the vehicle coordinate system at the rear axis, as in ISO8855)
        - SCS : Sensor Coordinate System (e.g. the camera coordinate system, or the lidar coordinate system)        
        - WCS : World Coordinate System (a static coordinate system for the entire scene, typically equal to the first LCS)
        - GCS : Geographic Coordinate System (UTM Universal Transverse Mercator)
        - ICS : Image coordinate system (this is the 2D image plane)

    For readability, let&#39;s use the following letter conventions:        
        - P : Pose 4x4
        - T : Transform 4x4
        - R : Rotation matrix 3x3        
        - C : Position of coordinate system wrt to another 3x1        
        - K : Camera calibration matrix 3x4
        - d : Distortion coefficients 1x5 (or 1x9, or 1x14)

    All Poses are defined right-handed. A Pose encodes the rotation and position of a coordinate system
    wrt to a reference system

    Usually, P_scs_wrt_lcs = [[R_3x3, C_3x1], [0, 0, 0, 1]]

    To actually convert a point from the reference system (e.g. LCS) into another system (e.g. SCS), the 
    transformation matrix is built as the inverse of the pose  
    https://en.wikipedia.org/wiki/Active_and_passive_transformation         

    Cameras coordinate systems are defined with X-to-right, Y-to-bottom, and Z-to-front.
    This is the common practice in computer vision, so that image coordinates are defined 
    x-to-right, y-to-bottom.

    Changes in coordinate systems are carried out using right-to-left matrix multiplication:
    e.g. X_scs = T_lcs_to_scs * X_lcs (e.g. X_lcs is 4x1, Transform_lcs_to_scs is 4x4, X_scs is 4x1)
         X_scs = T_lcs_to_scs * X_lcs

    In addition, transformations can be understood as inverse Poses.
    e.g. if T_lcs_to_scs converts a point from LCS to SCS, then 
            T_lcs_to_scs = np.linalg.inv(P_scs_wrt_lcs)            

    Note that to build a Pose and Transform by knowing the rotation R and position C of a coordinate system 
    wrt to another, it is possible to do:
    (pseudo-code)
    P = (R C; 0 0 0 1)
    or
    T = (R^T -R^TC; 0 0 0 1)
    Note P = T^-1 and T=P^-1     

    Since conversion from one system to another is useful, the following equations hold true:
    P_scs_wrt_lcs = (T_lcs_to_scs)^-1
    P_scs_wrt_lcs = T_scs_to_lcs


    ODOMETRY
    -----------------------------
    The sensors of the setup can move through time (e.g. if onboarded into a moving vehicle or drone), the
    motion of the set-up is defined by the odometry information.

    As each sensor has its own capturing timestamp, not necessarily coincident with the timestamp of
    an odometry entry, odometry information may be provided associated to a specific sensor frame (this way, 
    it is possible to locate globally sensing information from that sensor). 
    The library provides tools to interpolate odometry and associate odometry entries to specific timestamps. 

    The SCL library is defined in a way it is possible to add odometry values from multiple set-ups
    e.g. V2V, a second vehicle sends location information about itself and its sensors, along with detections 


    GEO-COORDINATES
    -----------------------------
    TODO

&#39;&#39;&#39;

# From https://dev.to/mxl/dijkstras-algorithm-in-python-algorithms-for-beginners-dkc
# we&#39;ll use infinity as a default distance to nodes.
inf = float(&#39;inf&#39;)
Edge = namedtuple(&#39;Edge&#39;, &#39;start, end, cost&#39;)


def make_edge(start, end, cost=1):
    return Edge(start, end, cost)


class Graph:
    def __init__(self, edges):
        # let&#39;s check that the data is right
        wrong_edges = [i for i in edges if len(i) not in [2, 3]]
        if wrong_edges:
            raise ValueError(&#39;Wrong edges data: {}&#39;.format(wrong_edges))

        self.edges = [make_edge(*edge) for edge in edges]

    @property
    def vertices(self):
        return set(
            sum(
                ([edge.start, edge.end] for edge in self.edges), []
            )
        )

    @staticmethod
    def get_node_pairs(n1, n2, both_ends=True):
        if both_ends:
            node_pairs = [[n1, n2], [n2, n1]]
        else:
            node_pairs = [[n1, n2]]
        return node_pairs

    def remove_edge(self, n1, n2, both_ends=True):
        node_pairs = self.get_node_pairs(n1, n2, both_ends)
        edges = self.edges[:]
        for edge in edges:
            if [edge.start, edge.end] in node_pairs:
                self.edges.remove(edge)

    def add_edge(self, n1, n2, cost=1, both_ends=True):
        node_pairs = self.get_node_pairs(n1, n2, both_ends)
        for edge in self.edges:
            if [edge.start, edge.end] in node_pairs:
                return ValueError(&#39;Edge {} {} already exists&#39;.format(n1, n2))

        self.edges.append(Edge(start=n1, end=n2, cost=cost))
        if both_ends:
            self.edges.append(Edge(start=n2, end=n1, cost=cost))

    @property
    def neighbours(self):
        neighbours = {vertex: set() for vertex in self.vertices}
        for edge in self.edges:
            neighbours[edge.start].add((edge.end, edge.cost))

        return neighbours

    def dijkstra(self, source, dest):
        assert source in self.vertices, &#39;Such source node doesn\&#39;t exist&#39;
        distances = {vertex: inf for vertex in self.vertices}
        previous_vertices = {
            vertex: None for vertex in self.vertices
        }
        distances[source] = 0
        vertices = self.vertices.copy()

        while vertices:
            current_vertex = min(
                vertices, key=lambda vertex: distances[vertex])
            vertices.remove(current_vertex)
            if distances[current_vertex] == inf:
                break
            for neighbour, cost in self.neighbours[current_vertex]:
                alternative_route = distances[current_vertex] + cost
                if alternative_route &lt; distances[neighbour]:
                    distances[neighbour] = alternative_route
                    previous_vertices[neighbour] = current_vertex

        path, current_vertex = deque(), dest
        while previous_vertices[current_vertex] is not None:
            path.appendleft(current_vertex)
            current_vertex = previous_vertices[current_vertex]
        if path:
            path.appendleft(current_vertex)
        return path


class Scene:
    def __init__(self, vcd):
        self.vcd = vcd
        self.cameras = dict()

    def camera_roi_z0(self, camera_name, cs, frameNum):
        &#34;&#34;&#34;
        This function computes the region of the image which maps into the reference (cs) Z=0 plane
        by checking whether the re-projected point lies in front or behind the camera
        :param cam_name: camera name
        :param frameNum: frame num
        :return: polygon 2D
        &#34;&#34;&#34;
        # Working on undistorted coordinates
        hline, points = self.compute_horizon_line(camera_name=camera_name, cs=cs, frameNum=frameNum)
        cam = self.get_camera(camera_name=camera_name, frameNum=frameNum)
        width = cam.img_size_undist[0]
        height = cam.img_size_undist[1]

        # Create 2 contours going through the limits of the image and using points
        # Then check which of them contains points which are projected in Z&gt;0 in camera coordinate system
        polygon = []
        if len(points) == 0:
            # So, the line at the infinite is NOT inside the limits of the image
            # Let&#39;s then check if any point inside the image produces a Z&gt;0 (if not, this camera is pointing to the sky)
            point2d_dist_3x1 = np.array([[width / 2, height / 2, 1]]).transpose()

            # Reproject into self.coordinate_system Z=0 plane
            point3d_4x1, valid = self.reproject_points2d_3xN(points2d_3xN=point2d_dist_3x1, plane=(0, 0, 1, 0),
                                                             cs_cam=camera_name, cs_dst=cs, frameNum=frameNum,
                                                             apply_undistorsion=False)
            # Transform back to camera coordinate system
            point3d_4x1 = self.transform_points3d_4xN(points3d_4xN=point3d_4x1, cs_src=cs, cs_dst=camera_name,
                                                      frameNum=frameNum)
            in_front = point3d_4x1[2, 0] &gt; 0
            if in_front:
                polygon.append((0, 0))
                polygon.append((width - 1, 0))
                polygon.append((width - 1, height - 1))
                polygon.append((0, height - 1))

                return polygon
        else:
            # Ok, so the horizon line is INSIDE the limits of the undistorted domain
            # There are 6 possible configurations
            points_code = []
            U = None
            L = None
            R = None
            B = None
            for idx, point in enumerate(points):
                if point[1] == 0:  # So points[0] is U
                    points_code.append(&#39;U&#39;)
                    U = point
                elif point[0] == width:
                    points_code.append(&#39;R&#39;)
                    R = point
                elif point[1] == height:
                    points_code.append(&#39;B&#39;)
                    B = point
                else:
                    points_code.append(&#39;L&#39;)
                    L = point
            UL = (0, 0)
            UR = (width - 1, 0)
            BR = (width - 1, height - 1)
            BL = (0, height - 1)

            polygon_A = []
            polygon_B = []
            if &#39;U&#39; in points_code and &#39;L&#39; in points_code:
                # Case 0: LU
                polygon_A.append(UL)
                polygon_A.append(U)
                polygon_A.append(L)
                polygon_A.append(U)
                polygon_B.append(UR)
                polygon_B.append(BR)
                polygon_B.append(BL)
                polygon_B.append(L)
            elif &#39;U&#39; in points_code and &#39;B&#39; in points_code:
                # Case 1: BU
                polygon_A.append(UL)
                polygon_A.append(U)
                polygon_A.append(B)
                polygon_A.append(BL)
                polygon_B.append(U)
                polygon_B.append(UR)
                polygon_B.append(BR)
                polygon_B.append(B)
            elif &#39;U&#39; in points_code and &#39;R&#39; in points_code:
                # Case 2: RU
                polygon_A.append(U)
                polygon_A.append(UR)
                polygon_A.append(R)
                polygon_B.append(UL)
                polygon_B.append(U)
                polygon_B.append(R)
                polygon_B.append(BR)
                polygon_B.append(BL)
            elif &#39;L&#39; in points_code and &#39;B&#39; in points_code:
                # Case 3: LB
                polygon_A.append(L)
                polygon_A.append(B)
                polygon_A.append(BL)
                polygon_B.append(UL)
                polygon_B.append(UR)
                polygon_B.append(BR)
                polygon_B.append(B)
                polygon_B.append(L)
            elif &#39;L&#39; in points_code and &#39;R&#39; in points_code:
                # Case 4: LR
                polygon_A.append(UL)
                polygon_A.append(UR)
                polygon_A.append(R)
                polygon_A.append(L)
                polygon_B.append(L)
                polygon_B.append(R)
                polygon_B.append(BR)
                polygon_B.append(BL)
            else:
                # Case 5: BR
                polygon_A.append(B)
                polygon_A.append(R)
                polygon_A.append(BR)
                polygon_B.append(UL)
                polygon_B.append(UR)
                polygon_B.append(R)
                polygon_B.append(B)
                polygon_B.append(BR)

            # Now test whether polygon or polygon_other contain points which project to z&gt;0 camera
            point_A = (sum(x for x, y in polygon_A), sum(y for x, y in polygon_A))
            point_A = (point_A[0]/len(polygon_A), point_A[1]/len(polygon_A))

            point_B = (sum(x for x, y in polygon_B), sum(y for x, y in polygon_B))
            point_B = (point_B[0] / len(polygon_B), point_B[1] / len(polygon_B))

            # Reproject into self.coordinate_system Z=0 plane
            point_A_3x1 = np.array([[point_A[0], point_A[1], 1]]).transpose()
            point_A_3d_4x1, valid = self.reproject_points2d_3xN(points2d_3xN=point_A_3x1, plane=(0, 0, 1, 0),
                                                                cs_cam=camera_name, cs_dst=cs, frameNum=frameNum,
                                                                apply_undistorsion=False)
            # Transform back to camera coordinate system
            point_A_3d_4x1 = self.transform_points3d_4xN(points3d_4xN=point_A_3d_4x1, cs_src=cs, cs_dst=camera_name,
                                                               frameNum=frameNum)
            in_front_A = point_A_3d_4x1[2, 0] &gt; 0

            if in_front_A:
                polygon = polygon_A
            else:
                # Check if B
                point_B_3x1 = np.array([[point_B[0], point_B[1], 1]]).transpose()
                point_B_3d_4x1, valid = self.reproject_points2d_3xN(points2d_3xN=point_B_3x1, plane=(0, 0, 1, 0),
                                                                    cs_cam=camera_name, cs_dst=cs, frameNum=frameNum,
                                                                    apply_undistorsion=False)
                # Transform back to camera coordinate system
                point_B_3d_4x1 = self.transform_points3d_4xN(points3d_4xN=point_B_3d_4x1, cs_src=cs, cs_dst=camera_name,
                                                               frameNum=frameNum)
                in_front_B = point_B_3d_4x1[2, 0] &gt; 0

                if in_front_B:
                    polygon = polygon_B
                else:
                    # This should not happen... something&#39;s wrong
                    pass

        N = len(polygon)
        points2d_3xN = np.ones((3, N), dtype=np.int32)
        count = 0
        for point in polygon:
            points2d_3xN[0, count] = utils.round(point[0])
            points2d_3xN[1, count] = utils.round(point[1])
            count += 1

        return points2d_3xN

    def compute_horizon_line(self, camera_name, cs, frameNum=None):
        &#34;&#34;&#34;
        This function computes the horizon line (as the projection of the infinite Z=0) for a camera at a certain
        frameNum, in image coordinates.
        It works by creating 2 virtual infinite points in the Z=0, and projecting them into the image and clipping
        it adequately.
        Works using undistorted coordinates (otherwise, the horizon line is not a line but a curve).
        :param camera_name: camera name
        :param frameNum: frame number
        :return: line in general form (a, b, c), and array of points, all in undistorted domain
        &#34;&#34;&#34;
        if frameNum is None:
            f = -1
        else:
            f = frameNum

        # Perhaps already computed
        # TODO check if we really need to store this computation
        if camera_name in self.cameras:
            if f in self.cameras[camera_name]:
                if &#39;hline&#39; in self.cameras[camera_name][f]:
                    return self.cameras[camera_name][f][&#39;hline&#39;]

        # Compute
        cam = self.get_camera(camera_name=camera_name, frameNum=frameNum)
        width = cam.width
        height = cam.height

        # Select points in the infinite that belong to the Z=0 plane
        # Let&#39;s propose several infinite points in all 360º directions
        steps = 60
        step = 2*np.pi / steps
        points3d_inf = np.zeros((4, steps))
        for s in range(0, steps):
            angle = step*s
            x = np.cos(angle)
            y = np.sin(angle)
            points3d_inf[0, s] = x
            points3d_inf[1, s] = y

        # Convert from cs to camera_cs
        points3d_inf = self.transform_points3d_4xN(points3d_4xN=points3d_inf,
                                                   cs_src=cs, cs_dst=camera_name,
                                                   frameNum=frameNum)

        # Project in the camera (USING UNDISTORTED FRAME)
        points2d_inf, valid = cam.project_points3d(points3d_4xN=points3d_inf, apply_distortion=False)
        points2d_inf = points2d_inf[:, valid]
        if points2d_inf.shape[1] &lt; 2:
            return np.array([[]]), []

        ## From here on we have at least 2 valid infinite points projected in the image
        #points2d_inf = cam.undistort_points2d(points2d_dist_3xN=points2d_inf)

        # Let&#39;s choose two points (first and last) to define the line (ideally all of them should lie in the same line)
        n = points2d_inf.shape[1]
        # TODO: test all lie in the same line

        line = np.cross(points2d_inf[:, 0], points2d_inf[:, -1])
        line = line / np.linalg.norm(line)

        a = line[0]
        b = line[1]
        c = line[2]

        # ax + by + c = 0
        num_points_touch = 0
        points_horz = []
        if abs(a) &lt; 1e-8:
            # There is no intersection with X
            point_int_x0 = (0, -c / b)
            point_int_xW = (width, -c / b)
            if 0 &lt;= -c / b &lt; height:
                num_points_touch = 2
                points_horz.append(point_int_x0)
                points_horz.append(point_int_xW)

        elif abs(b) &lt; 1e-8:
            # There is no intersection with Y
            point_int_y0 = (-c / a, 0)
            point_int_yH = (-c / a, height)
            if 0 &lt;= -c / a &lt; width:
                num_points_touch = 2
                points_horz.append(point_int_y0)
                points_horz.append(point_int_yH)
        else:
            P1 = (0, -c / b)
            if 0 &lt;= P1[1] &lt; height:
                points_horz.append(P1)
            P2 = (width, -(c + a * width) / b)
            if 0 &lt;= P2[1] &lt; height:
                points_horz.append(P2)
            P3 = (-c / a, 0)
            if 0 &lt;= P3[0] &lt; width:
                points_horz.append(P3)
            P4 = (-(c + b * height) / a, height)
            if 0 &lt;= P4[0] &lt; width:
                points_horz.append(P4)

            assert (len(points_horz) == 2 or len(
                points_horz) == 0)  # a line can only intersect a rectangle in 2 points! (or none)

        # Store for next time
        self.cameras.setdefault(camera_name, {})
        self.cameras[camera_name].setdefault(frameNum, {})
        self.cameras[camera_name][frameNum][&#39;hline&#39;] = line, points_horz

        return line, points_horz

    def get_camera(self, camera_name, frameNum=None, compute_remaps=False):
        &#34;&#34;&#34;
        This function explores the VCD content searching for the camera parameters of camera &#34;camera_name&#34;, specific
        for frameNum if specified (or static information if None).

        The function consults and updates a store of information self.cameras, to speed up some computations (so they
        are carried out only once).

        Returns an object of type Camera, which can be used to project points, undistort images, etc.
        :param camera_name: name of the camera
        :param frameNum: frame number (if None, static camera info is requested)
        :return: Camera object
        &#34;&#34;&#34;
        # Check if already computed
        if frameNum is None:
            f = -1
        else:
            f = frameNum

        if camera_name in self.cameras:
            if f in self.cameras[camera_name]:
                return self.cameras[camera_name][f][&#39;cam&#39;]

        # Create camera m
        camera = None
        if &#39;streams&#39; in self.vcd.data[&#39;vcd&#39;]:
            if camera_name in self.vcd.data[&#39;vcd&#39;][&#39;streams&#39;]:
                uri = self.vcd.data[&#39;vcd&#39;][&#39;streams&#39;][camera_name][&#39;uri&#39;]
                description = self.vcd.data[&#39;vcd&#39;][&#39;streams&#39;][camera_name][&#39;description&#39;]
                if &#39;stream_properties&#39; in self.vcd.data[&#39;vcd&#39;][&#39;streams&#39;][camera_name]:
                    sp = self.vcd.data[&#39;vcd&#39;][&#39;streams&#39;][camera_name][&#39;stream_properties&#39;]
                    if &#39;intrinsics_pinhole&#39; in sp:
                        camera = CameraPinhole(sp[&#39;intrinsics_pinhole&#39;], camera_name, description, uri, compute_remaps)
                    elif &#39;intrinsics_fisheye&#39; in sp:
                        camera = CameraFisheye(sp[&#39;intrinsics_fisheye&#39;], camera_name, description, uri, compute_remaps)
        else:
            return None

        if frameNum is not None:
            vcd_frame = self.vcd.get_frame(frameNum)

            if &#39;frame_properties&#39; in vcd_frame:
                if &#39;streams&#39; in vcd_frame[&#39;frame_properties&#39;]:
                    if camera_name in vcd_frame[&#39;frame_properties&#39;][&#39;streams&#39;]:
                        if &#39;stream_properties&#39; in vcd_frame[&#39;frame_properties&#39;][&#39;streams&#39;][camera_name]:
                            sp = vcd_frame[&#39;frame_properties&#39;][&#39;streams&#39;][camera_name][
                                &#39;stream_properties&#39;]
                        if &#39;intrinsics_pinhole&#39; in sp:
                            camera = CameraPinhole(sp[&#39;intrinsics_pinhole&#39;], camera_name, description, uri, compute_remaps)
                        elif &#39;intrinsics_fisheye&#39; in sp:
                            camera = CameraFisheye(sp[&#39;intrinsics_fisheye&#39;], camera_name, description, uri, compute_remaps)

        # Update store
        self.cameras.setdefault(camera_name, {})
        self.cameras[camera_name].setdefault(f, {})
        self.cameras[camera_name][f][&#39;cam&#39;] = camera

        return camera

    def __get_transform_chain(self, cs_src, cs_dst):
        # Create graph with the poses defined for each coordinate_system
        # These are poses valid &#34;statically&#34;
        lista = []
        for cs_name, cs_body in self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;].items():
            for child in cs_body[&#39;children&#39;]:
                lista.append((cs_name, child, 1))
                lista.append((child, cs_name, 1))

        graph = Graph(lista)
        result = graph.dijkstra(cs_src, cs_dst)
        return result

    def get_transform(self, cs_src, cs_dst, frameNum=None):
        &#34;&#34;&#34;
        This function finds a 4x4 transform from the specified source coordinate system into the destination coordinate
        system, in a way points in the cs_src domain can be transformed to the cs_dst.
        The function works finding the chain of transforms needed to go from src to dst by exploring the parent-child
        dependencies declated in VCD.

        If the frameNum is specified, the function searches if any specific transform step at frameNum. If not found,
        static transforms are returned.
        :param cs_src: source coordinate frame (e.g. &#34;CAM_LEFT&#34;, or &#34;WORLD&#34;)
        :param cs_dst: destination coordinate frame (e.g. &#34;VELO&#34;, or &#34;CAM_LEFT&#34;)
        :param frameNum: frame number where to look for specific transform steps
        :return: the 4x4 transform matrix, and a boolean that specifies if the transform is static or not
        &#34;&#34;&#34;
        assert (self.vcd.has_coordinate_system(cs_src))
        assert (self.vcd.has_coordinate_system(cs_dst))

        static = True
        if cs_src == cs_dst:
            return np.eye(4), static

        # Get chain of transforms
        chain = self.__get_transform_chain(cs_src, cs_dst)

        # Let&#39;s build the transform using atomic transforms (which exist in VCD)
        t_4x4 = np.identity(4, dtype=float)
        for counter, value in enumerate(chain):
            # e.g. a) result = {(&#34;cam_left&#34;, &#34;velo_top&#34;), (&#34;velo_top&#34;, &#34;vehicle-iso8855&#34;)}
            # e.g. b) result = {(&#34;vehicle-iso8855&#34;, &#34;velo_top&#34;), (&#34;velo_top&#34;, &#34;cam_left&#34;)}
            if counter == len(chain) - 1:
                break
            cs_1 = chain[counter]
            cs_2 = chain[counter + 1]

            t_name = cs_1 + &#34;_to_&#34; + cs_2
            t_name_inv = cs_2 + &#34;_to_&#34; + cs_1

            # NOTE: this entire function works under the consensus that pose_src_wrt_dst = transform_src_to_dst, using
            # alias rotation of coordinate systems and linear 4x4
            if frameNum is None:
                # No frame info, let&#39;s read from coordinate_system poses
                # Check if this edge is from child to parent or viceversa
                if cs_2 == self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_1][&#39;parent&#39;]:
                    t_4x4 = (
                        np.array([self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_1][&#39;pose_wrt_parent&#39;]]).reshape(4, 4)).dot(
                        t_4x4)
                elif cs_1 == self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_2][&#39;parent&#39;]:
                    temp = np.array([self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_2][&#39;pose_wrt_parent&#39;]])
                    t_4x4 = utils.inv(temp.reshape(4, 4)).dot(t_4x4)
            else:
                # So the user has asked for a specific frame, let&#39;s look for this frame if a transform exist
                transform_at_this_frame = False
                if frameNum in self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;]:
                    if &#39;frame_properties&#39; in self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum]:
                        if &#39;transforms&#39; in self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum][&#39;frame_properties&#39;]:
                            if t_name in self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum][&#39;frame_properties&#39;][&#39;transforms&#39;]:
                                transform = self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum][&#39;frame_properties&#39;][&#39;transforms&#39;][t_name]
                                t_4x4 = (np.array([transform[&#39;transform_src_to_dst_4x4&#39;]]).reshape(4, 4)).dot(t_4x4)
                                static = False  # with one non-static step the entire chain can be considered not static
                                transform_at_this_frame = True
                            elif t_name_inv in self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum][&#39;frame_properties&#39;][&#39;transforms&#39;]:
                                transform = self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum][&#39;frame_properties&#39;][&#39;transforms&#39;][
                                    t_name_inv]
                                temp = np.array([transform[&#39;transform_src_to_dst_4x4&#39;]])
                                t_4x4 = utils.inv(temp.reshape(4, 4)).dot(t_4x4)
                                static = False
                                transform_at_this_frame = True
                if not transform_at_this_frame:
                    # Reached this point means no transforms were defined at the requested frameNum
                    # Check if this edge is from child to parent or viceversa
                    if cs_2 == self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_1][&#39;parent&#39;]:
                        t_4x4 = (np.array([self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_1][&#39;pose_wrt_parent&#39;]]).reshape(4,
                                                                                                                    4)).dot(
                            t_4x4)
                    elif cs_1 == self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_2][&#39;parent&#39;]:
                        temp = np.array([self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_2][&#39;pose_wrt_parent&#39;]])
                        t_4x4 = utils.inv(temp.reshape(4, 4)).dot(t_4x4)

        return t_4x4, static

    def transform_points3d_4xN(self, points3d_4xN, cs_src, cs_dst, frameNum=None):
        transform_src_dst, static = self.get_transform(cs_src, cs_dst, frameNum)
        if transform_src_dst is not None:
            points3d_dst_4xN = utils.transform_points3d_4xN(points3d_4xN, transform_src_dst)
            return points3d_dst_4xN
        else:
            return None

    def transform_cuboid(self, cuboid_vals, cs_src, cs_dst, frameNum=None):
        transform_src_dst, static = self.get_transform(cs_src, cs_dst, frameNum)

        if transform_src_dst is not None:
            cuboid_vals_transformed = utils.transform_cuboid(cuboid_vals, transform_src_dst)
            return cuboid_vals_transformed
        else:
            return cuboid_vals

    def transform_plane(self, plane_abcd, cs_src, cs_dst, frameNum=None):
        transform_src_dst, static = self.get_transform(cs_src, cs_dst, frameNum)
        if transform_src_dst is not None:
            plane_abcd_transformed = utils.transform_plane(plane_abcd, transform_src_dst)
            return plane_abcd_transformed
        else:
            return plane_abcd

    def project_points3d_4xN(self, points3d_4xN, cs_src, cs_cam, frameNum=None, apply_distortion=True, remove_outside=False):
        &#34;&#34;&#34;
        This function projects 3D points into a given camera, specifying the origin coordinate system of the points,
        and a certain frame number. Optionally, distortion can be applied or not (e.g. sometimes is useful to project
        into the undistorted domain).
        :param points3d_4xN: array of 4xN 3D points in cs_src coordinate system
        :param cs_src: name of coordinate system of the points
        :param cs_cam: name of the camera
        :param frameNum: frame number (if None, static camera info is seeked)
        :param apply_distortion: default to True, if False, projection is carried out into undistorted domain
        :param remove_outside: flag to invalidate points outside the limits of the image domain
        :return: array of 3xN 2D points in image coordinates (distorted or undistorted according to apply_distortion),
        and array of boolean declaring points valid or not
        &#34;&#34;&#34;
        points3d_camera_cs_4xN = self.transform_points3d_4xN(points3d_4xN=points3d_4xN,
                                                             cs_src=cs_src, cs_dst=cs_cam,
                                                             frameNum=frameNum)
        if points3d_camera_cs_4xN is not None:
            cam = self.get_camera(camera_name=cs_cam, frameNum=frameNum)
            points2d_3xN, idx_valid = cam.project_points3d(points3d_4xN=points3d_camera_cs_4xN,
                                                           apply_distortion=apply_distortion,
                                                           remove_outside=remove_outside)
            return points2d_3xN, idx_valid
        return np.array([[]]), []

    def reproject_points2d_3xN(self, points2d_3xN, plane, cs_cam, cs_dst, frameNum=None, apply_undistorsion=True):
        # This function calls a camera (cs_cam) to reproject points2d in the image plane into
        # a plane defined in the cs_dst.
        # The obtained 3D points are expressed in cs_dst.
        # idx_valid identifies which points are valid 3D points (the reprojection might point to infinity)
        cam = self.get_camera(cs_cam, frameNum)
        plane_cam = self.transform_plane(plane, cs_dst, cs_cam, frameNum) # first convert plane into cam cs
        N = points2d_3xN.shape[1]
        points3d_3xN_cs_cam, idx_valid = cam.reproject_points2d(points2d_3xN, plane_cam, apply_undistorsion)
        if points3d_3xN_cs_cam.shape[1] &gt; 0:
            points3d_3xN_cs_cam_filt = points3d_3xN_cs_cam[:, idx_valid]
            points3d_4xN_cs_dst_filt = self.transform_points3d_4xN(points3d_3xN_cs_cam_filt, cs_cam, cs_dst, frameNum)
            points3d_4xN_cs_dst = np.full([4, N], np.nan)
            points3d_4xN_cs_dst[:, idx_valid] = points3d_4xN_cs_dst_filt
            return points3d_4xN_cs_dst, idx_valid
        return np.array([[]]), []


class Sensor:
    def __init__(self, name, description, uri, **properties):
        self.name = name
        self.description = description
        self.uri = uri
        self.type = type(self).__name__

        self.properties = properties  # additional properties

    def is_camera(self):
        if self.type == &#34;CameraPinhole&#34; or self.type == &#34;CameraFisheye&#34; or self.type == &#34;CameraEquirectangular&#34;:
            return True
        return False

    def is_lidar(self):
        if self.type == &#34;Lidar&#34;:
            return True
        return False


class Camera(Sensor):
    def __init__(self, width, height, name, description, uri):
        Sensor.__init__(self, name, description, uri)
        self.width = width
        self.height = height

        # This flags chooses between OpenCV&#39;s implementation of distort functions and manually written equations
        # They should render equal or very-similar results
        # OpenCV version might be faster (TBC)
        self.use_opencv = False
        pass

    def project_points3d(self, points3d_4xN, apply_distortion=True, remove_outside=False):
        pass

    def reproject_points2d(self, points2d_3xN, plane_cs):
        pass


class CameraPinhole(Camera):
    &#34;&#34;&#34;
    The Pinhole camera model defines a projection mechanism composed by two steps:

    - Linear projection: using the camera_matrix (K)
    - Radial/Tangential/... distortion: using distortion coefficients

    If distortion has 4 coefficients, it is assumed to be &#34;fisheye&#34; type, as in:
    https://docs.opencv.org/3.4/db/d58/group__calib3d__fisheye.html
    Otherwise (5 or more), it is assumed to be traditional &#34;radial&#34; distortion, as in:
    https://docs.opencv.org/4.2.0/d9/d0c/group__calib3d.html
    &#39;&#34;&#34;&#34;
    def __init__(self, camera_intrinsics, name, description, uri, compute_remaps=False):
        self.K_3x4 = np.array(camera_intrinsics[&#39;camera_matrix_3x4&#39;]).reshape(3, 4)
        rows, cols, = self.K_3x4.shape
        assert (rows == 3 and cols == 4)
        self.K_3x3 = utils.fromCameraMatrix3x4toCameraMatrix3x3(self.K_3x4)
        d_list = camera_intrinsics[&#39;distortion_coeffs_1xN&#39;]
        self.d_1xN = np.array(d_list).reshape(1, len(d_list))

        self.is_fisheye = len(d_list) == 4

        self.r_limit = None
        if self.is_distorted() and not self.is_fisheye:
            self.r_limit = utils.get_distortion_radius(self.d_1xN)

        # Pre-compute undistortion maps (LUTs)
        self.img_size_dist = (camera_intrinsics[&#39;width_px&#39;], camera_intrinsics[&#39;height_px&#39;])
        self.img_size_undist = (camera_intrinsics[&#39;width_px&#39;], camera_intrinsics[&#39;height_px&#39;])

        if self.is_distorted():
            # TODO: Add img_size_undist to user-defined params
            if self.is_fisheye:
                self.K_und_3x3 = cv.fisheye.estimateNewCameraMatrixForUndistortRectify(self.K_3x3, self.d_1xN,
                                                                                       self.img_size_dist, np.eye(3),
                                                                                       balance=1,
                                                                                       new_size=self.img_size_undist, fov_scale=1)

                self.mapX_to_und_16SC2 = None
                self.mapY_to_und_16SC2 = None
                if compute_remaps:
                    # NOTE: using m1type=cv.CV_16SC2 leads to fixed point representation, which is reported to be faster, but
                    # less accurate. In addition, interpreting the maps in 16SC2 is not trivial because there are indices
                    # of interpolated values (see https://docs.opencv.org/3.1.0/da/d54/group__imgproc__transform.html#gab75ef31ce5cdfb5c44b6da5f3b908ea4)
                    print(&#34;CameraPinhole(fisheye): Compute remaps for undistortion...&#34;)
                    self.__compute_remaps()

            else:
                # alpha = 0.0 means NO black points in undistorted image
                # alpha = 1.0 means ALL distorted points inside limits of undistorted image
                aux = cv.getOptimalNewCameraMatrix(self.K_3x3, self.d_1xN, self.img_size_dist, alpha=0.0,
                                                              newImgSize=self.img_size_undist)
                self.K_und_3x3 = aux[0]
                self.mapX_to_und_16SC2 = None
                self.mapY_to_und_16SC2 = None
                if compute_remaps:
                    self.__compute_remaps()

        else:
            self.K_und_3x3 = self.K_3x3

        self.K_und_3x4 = utils.fromCameraMatrix3x3toCameraMatrix3x4(self.K_und_3x3)

        Camera.__init__(self, camera_intrinsics[&#39;width_px&#39;],
                        camera_intrinsics[&#39;height_px&#39;],
                        name, description, uri)

    def __has_remaps(self):
        if self.mapX_to_und_16SC2 is None or self.mapY_to_und_16SC2 is None:
            return False
        return True

    def __compute_remaps(self):
        start = time.time()
        self.mapX_to_und_16SC2, self.mapY_to_und_16SC2 = cv.initUndistortRectifyMap(self.K_3x3, self.d_1xN,
                                                                                    R=np.eye(3),
                                                                                    newCameraMatrix=self.K_und_3x3,
                                                                                    size=self.img_size_undist,
                                                                                    m1type=cv.CV_16SC2)
        end = time.time()
        print(&#34;CameraPinhole(radial): Compute remaps for undistortion... &#34;, end - start)

    def __test_undistortion(self, img, img_und):
        # Let&#39;s test if we project a 3D point into the distorted image
        # and into the undistorted image
        # And convert from one into another
        # Conclusions would be: we can work in any domain (distorted or undistorted), and
        # keep the ability to project and reproject 3D points

        # 1.- Create some points
        N = 100
        points3d_4xN = np.ones((3, N))
        points3d_4xN[0:3, :] = points3d_4xN[0:3, :]*np.random.random((3, N))*10

        # 2.- Project points into distorted image
        points2d_3xN_dist, idx_valid = self.project_points3d(points3d_4xN)
        points2d_3xN_dist = points2d_3xN_dist[:, idx_valid]

        # 3.- Draw into image
        for i in range(0, points2d_3xN_dist.shape[1]):
            cv.circle(img, (utils.round(points2d_3xN_dist[0, i]),
                            utils.round(points2d_3xN_dist[1, i])), 2, (255, 0, 0), -1)

        # 4.- Undistort these points
        points2d_3xN_dist_und = self.undistort_points2d(points2d_3xN_dist)

    def undistort_image(self, img):
        if not self.is_distorted():
            return img
        if not self.__has_remaps():
            self.__compute_remaps()
        # cv.remap works for both models cv. and cv.fisheye
        return cv.remap(img, self.mapX_to_und_16SC2, self.mapY_to_und_16SC2, interpolation=cv.INTER_LINEAR,
                        borderMode=cv.BORDER_CONSTANT)

    def get_rays3d(self, point2d_3xN, K_3x3):
        rays3d_3xN = np.matmul((np.linalg.inv(K_3x3)), point2d_3xN)
        rays3d_3xN /= np.linalg.norm(rays3d_3xN)
        #ray3d_4xN = np.vstack((ray, np.ones((1, point2d_3xN.shape[1]))))
        #return ray3d_4xN
        return rays3d_3xN

    def is_distorted(self):
        return np.count_nonzero(self.d_1xN) &gt; 0

    def distort_points2d(self, points2d_und_3xN):
        &#34;&#34;&#34;
        This is a function to project from undistorted to distorted images.
        :param points2d_und_3xN: undistorted points 3xN homogeneous coordinates
        :return: distorted points 3xN homogeneous coordinates
        &#34;&#34;&#34;
        rays3d_und_3xN = utils.inv(self.K_und_3x3).dot(points2d_und_3xN)
        rays3d_dist_3xN = self.distort_rays3d(rays3d_und_3xN)
        points2d_dist_3xN = self.K_3x3.dot(rays3d_dist_3xN)
        return points2d_dist_3xN

    def undistort_points2d(self, points2d_dist_3xN):
        &#34;&#34;&#34;
        This function provides a mechanism to transfer from the distorted domain to the undistorted domain.

        E.g.
        img_und = self.camera.undistort_image(_img)
        points2d_und_3xN = self.camera.undistort_points2d(points2d_3xN)
        rows, cols = points2d_und_3xN.shape
        for i in range(0, cols):
            cv.circle(img_und, (utils.round(points2d_und_3xN[0, i]), utils.round(points2d_und_3xN[1, i])),
                2, (255, 255, 255), -1)
        cv.namedWindow(&#39;undistorted-test&#39;, cv.WINDOW_NORMAL)
        cv.imshow(&#39;undistorted-test&#39;, img_und)
        :param points2d_3xN: array of 2d points in homogeneous coordiantes 3xN
        :return: array of undistorted 2d points in homogeneous coordinates 3xN
        &#34;&#34;&#34;
        N = points2d_dist_3xN.shape[1]
        if N &lt; 1 or not self.is_distorted():
            return points2d_dist_3xN

        # Change shape from (3, N) to (N, 1, 2) so we can use OpenCV, removing homogeneous coordinate
        temp1 = points2d_dist_3xN[0:2, :]
        temp2 = utils.from_MxN_to_OpenCV_Nx1xM(temp1)

        # Use OpenCV functions
        if self.is_fisheye:
            temp3 = cv.fisheye.undistortPoints(temp2, self.K_3x3, self.d_1xN)
        else:
            temp3 = cv.undistortPoints(temp2, self.K_3x3, self.d_1xN)

        # Reshape to (3, N)
        temp3.shape = (N, 2)
        points2d_und_3xN = np.vstack((temp3.T, np.ones((1, N))))

        # Map into undistorted domain by using K_3x3_und
        points2d_und_3xN = self.K_und_3x3.dot(points2d_und_3xN)

        test = False
        if test:
            points2d_dist_re_3xN = self.distort_points2d(points2d_und_3xN)
            error = np.linalg.norm(points2d_dist_re_3xN - points2d_dist_3xN)
            print(&#34;Undistortion error: &#34;, error)

        return points2d_und_3xN

    def distort_rays3d(self, rays3d_3xN):
        &#34;&#34;&#34;
        This function distort 3d rays according to the distortion function.
        :param rays3d_3xN: 3d rays as 3xN arrays
        :return: distorted 3d rays as 3xN arrays after applying distortion function.
        &#34;&#34;&#34;
        N = rays3d_3xN.shape[1]
        if N == 0 or not self.is_distorted():
            rays3d_dist_3xN = np.array([[]])
            return rays3d_dist_3xN

        # Normalize so last coordinate is 1
        rays3d_3xN[0:3, :] = rays3d_3xN[0:3, :] / rays3d_3xN[2, :]

        if self.is_fisheye:
            temp0 = rays3d_3xN[0:2, :]  # remove homogeneous coordinate
            temp1 = utils.from_MxN_to_OpenCV_Nx1xM(temp0)  # Change shape to (N, 1, 2)
            temp2 = cv.fisheye.distortPoints(temp1, np.eye(3), self.d_1xN)  # apply distortion using an identity K
            temp2.shape = (N, 2)  # reshape to 2xN
            rays3d_dist_3xN = np.vstack((temp2.T, np.ones((1, temp2.shape[0]))))  # add homog. row so it is 3xN
        else:
            # NOTE: there is no cv.distortPoints() function as in cv.fisheye.distortPoints()
            # It is though possible to distort points using OpenCV by using cv.projectPoints function
            # As we don&#39;t want to use K matrices here, let&#39;s use an eye, so the results are rays and not points
            aux = cv.projectPoints(objectPoints=rays3d_3xN,
                                   rvec=np.array([[[0., 0., 0.]]]),
                                   tvec=np.array([[[0., 0., 0.]]]),
                                   cameraMatrix=np.eye(3),
                                   distCoeffs=self.d_1xN)
            rays3d_dist_3xN = utils.from_OpenCV_Nx1xM_to_MxN(aux[0])
            rays3d_dist_3xN = np.vstack((rays3d_dist_3xN.transpose(), np.ones((1, N))))

        return rays3d_dist_3xN

    def project_points3d(self, points3d_4xN, apply_distortion=True, remove_outside=False):
        &#34;&#34;&#34;
        This function projects 3D points into 2D points using the camera projection.
        All coordinates as homogeneous coordinates, and all 3D elements expressed wrt the camera coordinate system.

        If apply_distortion is False, the projection produces points in the undistorted image.
        If apply_distortion is True, the distortion process (if any) is applied into the distorted image.

        First, the 3D points are understood as 3D rays.
        If distorted, the rays3D are distorted into distorted rays3D.

        The calibration matrix K_3x3 or K_3x3_und (according to apply_distortion) is applied to produce points.

        Points outside limits are removed if remove_outside is True.

        :param points3d_4xN: 3D points in camera cs, homogeneous coordinates
        :param apply_distortion: flag to determine whether to project into distorted or undistorted domain
        :param remove_outside: flag to remove points that fall outside the limits of the target image
        :return: 2D points in image plane, as 3xN array, in hom. coordinates, and boolean array of valid
        &#34;&#34;&#34;

        # 0.- Pre-filter
        assert (points3d_4xN.ndim == 2)
        N = points3d_4xN.shape[1]
        if N == 0:
            return np.array([[]]), []

        # 1.- Select only those z &gt; 0 (in front of the camera)
        idx_in_front = points3d_4xN[2, :] &gt; 1e-8
        idx_valid = idx_in_front

        # 2.- Distort rays3d if distorted
        rays3d_3xN_filt = points3d_4xN[0:3, idx_valid]
        rays3d_3xN_filt = rays3d_3xN_filt[0:3, :] / rays3d_3xN_filt[2, :]  # so (x&#39;, y&#39;, 1), convenient for dist.
        rays3d_3xN = np.full([3, N], np.nan)
        rays3d_3xN[:, idx_valid] = rays3d_3xN_filt

        if self.is_distorted():
            if not self.is_fisheye:
                if self.r_limit is not None:
                    for i in range(0, N):
                        if idx_valid[i]:  # ignore those already filtered
                            xp = rays3d_3xN[0, i] / rays3d_3xN[2, i]  # this is x&#39;=x/z as in opencv docs
                            yp = rays3d_3xN[1, i] / rays3d_3xN[2, i]  # this is y&#39;=y/z
                            r = np.sqrt(xp * xp + yp * yp)

                            if r &gt;= self.r_limit * 0.8:  # 0.8 to also remove very close to limit
                                idx_valid[i] = False
                                rays3d_3xN[:, i] = np.nan

            if apply_distortion:
                # Now distort (only non-nans)
                rays3d_3xN_filt = rays3d_3xN[:, idx_valid]
                rays3d_3xN_filt_dist = self.distort_rays3d(rays3d_3xN_filt) # no nan should go into it

                # Add nans
                rays3d_3xN = np.full([3, N], np.nan)
                rays3d_3xN[:, idx_valid] = rays3d_3xN_filt_dist

        # 3.- Project using calibration matrix
        if apply_distortion:
            points2d_3xN = self.K_3x3.dot(rays3d_3xN)
            if remove_outside:
                points2d_3xN, idx_valid = utils.filter_outside(points2d_3xN, self.img_size_dist, idx_valid)
        else:
            points2d_3xN = self.K_und_3x3.dot(rays3d_3xN)
            if remove_outside:
                points2d_3xN, idx_valid = utils.filter_outside(points2d_3xN, self.img_size_undist, idx_valid)

        return points2d_3xN, idx_valid

    def reproject_points2d(self, points2d_3xN, plane_cs, apply_undistorsion = True):
        &#34;&#34;&#34;
        This function takes 2D points in the (distorted) image and traces back a 3D ray from the camera optical axis
        through the point and gets the intersection with a defined world plane (in the form (a, b, c, d)).

        This function takes distortion into consideration, by first undistorting the 2D points, and then raycasting
        the 3D ray, free of distortion to apply Plücker formulation to obtain the intersection of a 3D line with
        a 3D plane.

        To manage tha case where the back-projection does not intersect the plane (which can happen for parallel set
        -ups of infinite points), the function returns an array of booleans that define the validity of the projection.

        :param points2D_3xN: array 2D points as 3XN array of homogeneous coordinates, representing points in the original
        image
        :param plane_cs: a plane expressed in general form (a, b, c, d) expressing a 3D plane in camera coordinate
        system
        :return: returns an array of 3D points (4xN array) in homogeneous coordinates, expressed in the camera
        coordinate systems, belonging to the world plane; and a 1xN array of booleans.
        &#34;&#34;&#34;
        # First, undistort point, so we can project back linear rays
        points2d_und_3xN = points2d_3xN
        if self.is_distorted() and apply_undistorsion:
            points2d_und_3xN = self.undistort_points2d(points2d_3xN)

        N = points2d_und_3xN.shape[1]
        if N == 0:
            return np.array([[]]), []
        idx_valid = [True] * N

        # Get ray 3D (expressed in camera coordinate system)
        rays3d_3xN = self.get_rays3d(points2d_und_3xN, self.K_und_3x3)

        # Use Plucker intersection line-plane
        # Create Plucker line using 2 points: origin of camera and origin of camera + ray
        P1 = np.vstack((0, 0, 0, 1))
        P2array = np.vstack((rays3d_3xN, np.ones((1, N))))
        # Plane equation in plucker coordinates (wrt to world)
        P = np.asarray(plane_cs).reshape(4, 1)
        # Line equation in plucker coordinates
        p3dNx4 = np.array([])
        count = 0
        for P2 in P2array.T:
            P2 = P2.reshape(4, 1)
            L = np.matmul(P1, np.transpose(P2)) - np.matmul(P2, np.transpose(P1))
            # Intersection is a 3D point
            p3Dlcs = np.matmul(L, P)
            if p3Dlcs[3][0] != 0:
                p3Dlcs /= p3Dlcs[3][0]  # homogeneous
            else:
                # This is an infinite point: return direction vector instead
                norm = np.linalg.norm(p3Dlcs[:3][0])
                p3Dlcs /= norm
                idx_valid[count] = False
            p3dNx4 = np.append(p3dNx4, p3Dlcs)
            count += 1
        p3dNx4 = p3dNx4.reshape(p3dNx4.shape[0] // 4, 4)
        p3d_4xN = np.transpose(p3dNx4)
        return p3d_4xN, idx_valid


class CameraFisheye(Camera):
    def __init__(self, camera_intrinsics, name, description, uri, compute_remaps=False):
        self.cx = camera_intrinsics[&#39;center_x&#39;]
        self.cy = camera_intrinsics[&#39;center_y&#39;]
        self.img_size_dist = (camera_intrinsics[&#39;width_px&#39;], camera_intrinsics[&#39;height_px&#39;])
        self.img_size_undist = (camera_intrinsics[&#39;width_px&#39;], camera_intrinsics[&#39;height_px&#39;])

        # Note: This K_3x4 has focal length 1.0 because this way we can split the projection process
        # in two steps, first distort the rays using teh angle of incidence-to-radius polynomial
        # and second, apply the conversion to the image plane, which under this model is just a translation in pixels,
        # and not a linear projection as with the CameraPinhole model
        self.K_3x4 = np.array([[1.0, 0.0, self.img_size_dist[0] / 2.0 + self.cx, 0.0],
                               [0.0, 1.0, self.img_size_dist[1] / 2.0 + self.cy, 0.0],
                               [0.0, 0.0, 1.0, 0.0]])
        self.K_3x3 = utils.fromCameraMatrix3x4toCameraMatrix3x3(self.K_3x4)

        # Direct distortion (from angle of incidence to radius in image)
        self.d_1x4 = np.array(camera_intrinsics[&#39;lens_coeffs_1x4&#39;]).reshape(1, 4)

        # Inverse distortion (from radius in image to incidence angle)
        self.d_inv_1x4 = self.__invert_polynomial(self.d_1x4)

        self.K_und_3x3 = self.estimate_new_camera_matrix_for_undistort_rectify(img_size_orig=self.img_size_dist,
                                                                               balance=0.9,
                                                                               img_size_dst=self.img_size_undist,
                                                                               fov_scale=1.0)
        self.K_und_3x4 = utils.fromCameraMatrix3x3toCameraMatrix3x4(self.K_und_3x3)

        self.mapX_to_und_16SC2 = None
        self.mapY_to_und_16SC2 = None

        if compute_remaps:
            self.__compute_remaps()

        Camera.__init__(self, camera_intrinsics[&#39;width_px&#39;],
                        camera_intrinsics[&#39;height_px&#39;],
                        name, description, uri)

    def __has_remaps(self):
        if self.mapX_to_und_16SC2 is None or self.mapY_to_und_16SC2 is None:
            return False
        return True

    def __compute_remaps(self):
        start = time.time()
        self.mapX_to_und_16SC2, self.mapY_to_und_16SC2 = self.init_undistort_rectify_map(self.K_und_3x3,
                                                                                         self.img_size_undist)
        end = time.time()
        print(&#34;CameraFisheye: Compute remaps for undistortion... &#34;, end - start)

    def __apply_polynomial(self, x, k1, k2, k3, k4):
        x2 = x * x
        x3 = x2 * x
        x4 = x3 * x
        y = x * k1 + x2 * k2 + x3 * k3 + x4 * k4
        return y

    def __invert_polynomial(self, d, n=100):
        a = np.linspace(0, np.pi/2, num=n)
        k1 = d[0, 0]
        k2 = d[0, 1]
        k3 = d[0, 2]
        k4 = d[0, 3]
        rp = self.__apply_polynomial(a, k1, k2, k3, k4)
        kp = np.polyfit(rp, a, 4)
        kp1 = kp[3]
        kp2 = kp[2]
        kp3 = kp[1]
        kp4 = kp[0]

        a_rep = self.__apply_polynomial(rp, kp1, kp2, kp3, kp4)

        error_a = np.sum(np.abs(a-a_rep)) / n
        error_a_deg = error_a * 180 / np.pi

        if error_a_deg &gt; 1e-1:
            warnings.warn(&#34;WARNING: the inverse of the CameraFisheye distortion produces reprojection error &gt; 1e-2 &#34;
                          &#34;(i.e. higher than tenth of degree&#34;)

        return np.array([[kp1, kp2, kp3, kp4]])

    def undistort_image(self, img):
        if not self.is_distorted():
            return img
        if not self.__has_remaps():
            self.__compute_remaps()
        return cv.remap(img, self.mapX_to_und_16SC2, self.mapY_to_und_16SC2, interpolation=cv.INTER_LINEAR,
                        borderMode=cv.BORDER_CONSTANT)

    def undistort_points2d(self, points2d_dist_3xN):
        # This is a transfer from the distorted to the undistorted
        rays3d_dist_3xN = utils.inv(self.K_3x3).dot(points2d_dist_3xN)
        rays3d_und_3xN = self.undistort_rays3d(rays3d_dist_3xN)
        points2d_und_3xN = self.K_und_3x3.dot(rays3d_und_3xN)

        return points2d_und_3xN

    def distort_points2d(self, points2d_und_3xN):
        # This is a transfer from the undistorted domain to the distorted
        rays3d_und_3xN = utils.inv(self.K_und_3x3).dot(points2d_und_3xN)
        rays3d_dist_3xN = self.distort_rays3d(rays3d_und_3xN) # TODO: better to use self.project_points?
        points2d_dist_3xN = self.K_3x3.dot(rays3d_dist_3xN)

        return points2d_dist_3xN

    def is_distorted(self):
        return np.count_nonzero(self.d_1x4) &gt; 0

    def undistort_rays3d(self, rays3d_dist_3xN):
        &#34;&#34;&#34;
        This function undistort 3d rays according to the inverse polynomial function.
        :param rays3d_dist_3xN: 3d rays (connecting optical center and image plane using K)
        :return: undistorted rays as 3xN
        &#34;&#34;&#34;
        N = rays3d_dist_3xN.shape[1]
        if N == 0 or not self.is_distorted():
            rays3d_und_3xN = np.array([[]])
            return rays3d_und_3xN

        rays3d_und_3xN = np.zeros((3, N))
        for i in range(0, N):
            X = rays3d_dist_3xN[0, i]
            Y = rays3d_dist_3xN[1, i]
            rp = utils.norm([X, Y])
            a = self.__apply_polynomial(rp, self.d_inv_1x4[0, 0],
                                         self.d_inv_1x4[0, 1],
                                         self.d_inv_1x4[0, 2],
                                         self.d_inv_1x4[0, 3])
            r = math.tan(a)
            r_rp = np.float(r / rp)
            if rp &gt; 1e-8:
                rays3d_und_3xN[0, i] = X * r_rp
                rays3d_und_3xN[1, i] = Y * r_rp
                rays3d_und_3xN[2, i] = 1
            else:
                rays3d_und_3xN[0, i] = 0
                rays3d_und_3xN[1, i] = 0
                rays3d_und_3xN[2, i] = 1

        return rays3d_und_3xN

    def distort_rays3d(self, rays3d_3xN):
        &#34;&#34;&#34;
        This function distort 3d rays according to the distortion function.
        :param rays3d_3xN: 3d rays as 3xN arrays
        :return: distorted 3d rays as 3xN arrays after applying distortion function.
        &#34;&#34;&#34;
        N = rays3d_3xN.shape[1]
        if N == 0 or not self.is_distorted():
            rays3d_dist_3xN = np.array([[]])
            return rays3d_dist_3xN

        rays3d_dist_3xN = np.zeros((3, N))
        for i in range(0, N):
            X = rays3d_3xN[0, i]
            Y = rays3d_3xN[1, i]
            Z = rays3d_3xN[2, i]
            r = utils.norm([X, Y])
            a = math.atan2(r, Z)
            rp = self.__apply_polynomial(a, self.d_1x4[0, 0], self.d_1x4[0, 1], self.d_1x4[0, 2], self.d_1x4[0, 3])
            rp_r = np.float(rp/r)
            if r &gt; 1e-8:
                rays3d_dist_3xN[0, i] = X*rp_r
                rays3d_dist_3xN[1, i] = Y*rp_r
                rays3d_dist_3xN[2, i] = 1
            else:
                rays3d_dist_3xN[0, i] = 0
                rays3d_dist_3xN[1, i] = 0
                rays3d_dist_3xN[2, i] = 1

        return rays3d_dist_3xN

    def project_points3d(self, points3d_4xN, apply_distortion=True, remove_outside=False):
        &#34;&#34;&#34;
        This function projects 3d points in camera coordinate system using the angle-of-incidence projection model.
        Any 3D point in space P=(X,Y,Z,1)^T has a radius with respect to the optical axis Z
        r = ||X^2 + Y^2||
        The angle of incidence to the optical center is
        a = atan(r/Z)
        The angle of incidence then spans from 0 to pi/2
        The model of the lens relates the angle of incidence with the radius of the point in the image plane (in pixels):
        rp = k1*a + k2*a^2 + k3*a^3 + k4*a^4
        Then, the point in the image plane is recovered from rp as:
        p = (X*rp/r + w/2 + cx, Y*rp/r + h/2 + cy)

        If apply_distortion is True, the projection creates points in the distorted domain.
        If apply_distortion is False, the projection creates points in the undistorted domain (NOT IMPLEMENTED!).

        :param points3d_4xN: 3D points in camera coordinate system
        :param apply_distortion: boolean to obtain points in the distorted domain.
        :param remove_outside: filter out points that fall outside the limits of the image frame.
        :return: 2D points in image plane, as 3xN array, in hom. coordinates, and boolean array of valid
        &#34;&#34;&#34;
        # 0.- Pre-filter
        assert (points3d_4xN.ndim == 2)
        N = points3d_4xN.shape[1]
        if N == 0:
            return np.array([[]]), []

        # 1.- Select only those z &gt; 0 (in front of the camera)
        idx_in_front = points3d_4xN[2, :] &gt; 1e-8
        idx_valid = idx_in_front

        # 2.- Distort rays3d if distorted
        rays3d_3xN_filt = points3d_4xN[0:3, idx_valid]
        rays3d_3xN_filt = rays3d_3xN_filt[0:3, :] / rays3d_3xN_filt[2, :]  # so (x&#39;, y&#39;, 1), convenient for dist.
        rays3d_3xN = np.full([3, N], np.nan)
        rays3d_3xN[:, idx_valid] = rays3d_3xN_filt

        if apply_distortion:
            # Now distort (only non-nans)
            rays3d_3xN_filt = rays3d_3xN[:, idx_valid]
            rays3d_3xN_filt_dist = self.distort_rays3d(rays3d_3xN_filt)  # no nan should go into it


            # DEBUG
            #temp = self.undistort_rays3d(rays3d_3xN_filt_dist)
            #error = np.linalg.norm(rays3d_3xN_filt - temp)

            # Add nans
            rays3d_3xN = np.full([3, N], np.nan)
            rays3d_3xN[:, idx_valid] = rays3d_3xN_filt_dist

        # 3.- Project using calibration matrix
        if apply_distortion:
            points2d_3xN = self.K_3x3.dot(rays3d_3xN)
            if remove_outside:
                points2d_3xN, idx_valid = utils.filter_outside(points2d_3xN, self.img_size_dist, idx_valid)
        else:
            if not self.__has_remaps():
                self.__compute_remaps()
            points2d_3xN = self.K_und_3x3.dot(rays3d_3xN)
            if remove_outside:
                points2d_3xN, idx_valid = utils.filter_outside(points2d_3xN, self.img_size_undist, idx_valid)

        return points2d_3xN, idx_valid

    def init_undistort_rectify_map(self, K_und_3x3, img_size_undist):
        # Create maps
        w = img_size_undist[0]
        h = img_size_undist[1]
        map1 = np.zeros((h, w), dtype=np.float32)
        map2 = np.zeros((h, w), dtype=np.float32)

        # Loop over undistorted domain
        for i in range(0, h):
            # Read all pixel pos of this row
            points2d_und_3xN = np.array([np.linspace(0, w-1, num=w),
                                    i*np.ones(w),
                                    np.ones(w)])

            # Un-apply K_und to get the undistorted ray
            ray3d_und_3xN = utils.inv(K_und_3x3).dot(points2d_und_3xN)
            ray3d_und_3xN[0:3, :] = ray3d_und_3xN[0:3, :] / ray3d_und_3xN[2, :]
            ray3d_und_4xN = np.vstack((ray3d_und_3xN, np.ones(w)))

            # Project
            points2d_dist_3xN, idx_valid = self.project_points3d(ray3d_und_4xN)

            # Assign into map
            map1[i, :] = points2d_dist_3xN[0, :]
            map2[i, :] = points2d_dist_3xN[1, :]

        # Return the maps
        return map1, map2

    def estimate_new_camera_matrix_for_undistort_rectify(self, img_size_orig, balance, img_size_dst, fov_scale):
        balance = min(max(balance, 0.0), 1.0)
        w = img_size_orig[0]
        h = img_size_orig[1]
        romboid_points = np.array([[w/2, 0, 1],
                                   [w, h/2, 1],
                                   [w/2, h, 1],
                                   [0, h/2, 1]]).transpose()

        rays3d_und_3xN = self.undistort_rays3d(romboid_points)
        center_mass = cv.mean(rays3d_und_3xN)
        cn = center_mass
        aspect_ratio = 1.0

        # Find maxima
        minx = float(&#39;inf&#39;)
        miny = float(&#39;inf&#39;)
        maxx = -float(&#39;inf&#39;)
        maxy = -float(&#39;inf&#39;);
        for i in range(0, 4):
            miny = min(miny, rays3d_und_3xN[1, i])
            maxy = max(maxy, rays3d_und_3xN[1, i])
            minx = min(minx, rays3d_und_3xN[0, i])
            maxx = max(maxx, rays3d_und_3xN[0, i])

        f1 = w *0.5/(cn[0] - minx)
        f2 = w * 0.5 / (maxx - cn[0])
        f3 = h * 0.5 * aspect_ratio / (cn[1] - miny)
        f4 = h * 0.5 * aspect_ratio / (maxy - cn[1])

        fmin = min(f1, min(f2, min(f3, f4)))
        fmax = max(f1, max(f2, max(f3, f4)))

        f = balance * fmin + (1.0 - balance)*fmax
        if fov_scale &gt; 0:
            f *= (1.0/fov_scale)

        new_f = (f, f/aspect_ratio)
        new_c = (w*0.5 - cn[0] * f, ((h*aspect_ratio)*0.5 - cn[0] * f)/aspect_ratio)

        rx = img_size_dst[0] / img_size_orig[0]
        ry = img_size_dst[1] / img_size_orig[1]

        K_new = np.array([[new_f[0]*rx, 0, new_c[0]*rx],
                          [0, new_f[1]*ry, new_c[1]*ry],
                          [0, 0, 1]])

        return K_new

    def reproject_points2d(self, points2d_3xN, plane_cs, apply_undistorsion=True):
        N = points2d_3xN.shape[1]
        if N == 0:
            return np.array([[]]), []
        idx_valid = [True] * N

        # Undistort rays
        if apply_undistorsion:
            # First, get rays3d applying K^-1
            rays3d_dist_3xN = utils.inv(self.K_3x3).dot(points2d_3xN)
            rays3d_3xN = self.undistort_rays3d(rays3d_dist_3xN=rays3d_dist_3xN)
        else:
            # For those cases where this function is given undistorted points
            rays3d_dist_3xN = utils.inv(self.K_und_3x3).dot(points2d_3xN)
            rays3d_3xN = rays3d_dist_3xN

        # Use Plucker intersection line-plane
        # Create Plucker line using 2 points: origin of camera and origin of camera + ray
        P1 = np.vstack((0, 0, 0, 1))
        P2array = np.vstack((rays3d_3xN, np.ones((1, N))))
        # Plane equation in plucker coordinates (wrt to world)
        P = np.asarray(plane_cs).reshape(4, 1)
        # Line equation in plucker coordinates
        p3dNx4 = np.array([])
        count = 0
        for P2 in P2array.T:
            P2 = P2.reshape(4, 1)
            L = np.matmul(P1, np.transpose(P2)) - np.matmul(P2, np.transpose(P1))
            # Intersection is a 3D point
            p3Dlcs = np.matmul(L, P)
            if p3Dlcs[3][0] != 0:
                p3Dlcs /= p3Dlcs[3][0]  # homogeneous
            else:
                # This is an infinite point: return direction vector instead
                norm = np.linalg.norm(p3Dlcs[:3][0])
                p3Dlcs /= norm
                idx_valid[count] = False
            p3dNx4 = np.append(p3dNx4, p3Dlcs)
            count += 1
        p3dNx4 = p3dNx4.reshape(p3dNx4.shape[0] // 4, 4)
        p3d_4xN = np.transpose(p3dNx4)
        return p3d_4xN, idx_valid</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="vcd.scl.make_edge"><code class="name flex">
<span>def <span class="ident">make_edge</span></span>(<span>start, end, cost=1)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_edge(start, end, cost=1):
    return Edge(start, end, cost)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="vcd.scl.Camera"><code class="flex name class">
<span>class <span class="ident">Camera</span></span>
<span>(</span><span>width, height, name, description, uri)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Camera(Sensor):
    def __init__(self, width, height, name, description, uri):
        Sensor.__init__(self, name, description, uri)
        self.width = width
        self.height = height

        # This flags chooses between OpenCV&#39;s implementation of distort functions and manually written equations
        # They should render equal or very-similar results
        # OpenCV version might be faster (TBC)
        self.use_opencv = False
        pass

    def project_points3d(self, points3d_4xN, apply_distortion=True, remove_outside=False):
        pass

    def reproject_points2d(self, points2d_3xN, plane_cs):
        pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="vcd.scl.Sensor" href="#vcd.scl.Sensor">Sensor</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="vcd.scl.CameraFisheye" href="#vcd.scl.CameraFisheye">CameraFisheye</a></li>
<li><a title="vcd.scl.CameraPinhole" href="#vcd.scl.CameraPinhole">CameraPinhole</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="vcd.scl.Camera.project_points3d"><code class="name flex">
<span>def <span class="ident">project_points3d</span></span>(<span>self, points3d_4xN, apply_distortion=True, remove_outside=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def project_points3d(self, points3d_4xN, apply_distortion=True, remove_outside=False):
    pass</code></pre>
</details>
</dd>
<dt id="vcd.scl.Camera.reproject_points2d"><code class="name flex">
<span>def <span class="ident">reproject_points2d</span></span>(<span>self, points2d_3xN, plane_cs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reproject_points2d(self, points2d_3xN, plane_cs):
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="vcd.scl.CameraFisheye"><code class="flex name class">
<span>class <span class="ident">CameraFisheye</span></span>
<span>(</span><span>camera_intrinsics, name, description, uri, compute_remaps=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CameraFisheye(Camera):
    def __init__(self, camera_intrinsics, name, description, uri, compute_remaps=False):
        self.cx = camera_intrinsics[&#39;center_x&#39;]
        self.cy = camera_intrinsics[&#39;center_y&#39;]
        self.img_size_dist = (camera_intrinsics[&#39;width_px&#39;], camera_intrinsics[&#39;height_px&#39;])
        self.img_size_undist = (camera_intrinsics[&#39;width_px&#39;], camera_intrinsics[&#39;height_px&#39;])

        # Note: This K_3x4 has focal length 1.0 because this way we can split the projection process
        # in two steps, first distort the rays using teh angle of incidence-to-radius polynomial
        # and second, apply the conversion to the image plane, which under this model is just a translation in pixels,
        # and not a linear projection as with the CameraPinhole model
        self.K_3x4 = np.array([[1.0, 0.0, self.img_size_dist[0] / 2.0 + self.cx, 0.0],
                               [0.0, 1.0, self.img_size_dist[1] / 2.0 + self.cy, 0.0],
                               [0.0, 0.0, 1.0, 0.0]])
        self.K_3x3 = utils.fromCameraMatrix3x4toCameraMatrix3x3(self.K_3x4)

        # Direct distortion (from angle of incidence to radius in image)
        self.d_1x4 = np.array(camera_intrinsics[&#39;lens_coeffs_1x4&#39;]).reshape(1, 4)

        # Inverse distortion (from radius in image to incidence angle)
        self.d_inv_1x4 = self.__invert_polynomial(self.d_1x4)

        self.K_und_3x3 = self.estimate_new_camera_matrix_for_undistort_rectify(img_size_orig=self.img_size_dist,
                                                                               balance=0.9,
                                                                               img_size_dst=self.img_size_undist,
                                                                               fov_scale=1.0)
        self.K_und_3x4 = utils.fromCameraMatrix3x3toCameraMatrix3x4(self.K_und_3x3)

        self.mapX_to_und_16SC2 = None
        self.mapY_to_und_16SC2 = None

        if compute_remaps:
            self.__compute_remaps()

        Camera.__init__(self, camera_intrinsics[&#39;width_px&#39;],
                        camera_intrinsics[&#39;height_px&#39;],
                        name, description, uri)

    def __has_remaps(self):
        if self.mapX_to_und_16SC2 is None or self.mapY_to_und_16SC2 is None:
            return False
        return True

    def __compute_remaps(self):
        start = time.time()
        self.mapX_to_und_16SC2, self.mapY_to_und_16SC2 = self.init_undistort_rectify_map(self.K_und_3x3,
                                                                                         self.img_size_undist)
        end = time.time()
        print(&#34;CameraFisheye: Compute remaps for undistortion... &#34;, end - start)

    def __apply_polynomial(self, x, k1, k2, k3, k4):
        x2 = x * x
        x3 = x2 * x
        x4 = x3 * x
        y = x * k1 + x2 * k2 + x3 * k3 + x4 * k4
        return y

    def __invert_polynomial(self, d, n=100):
        a = np.linspace(0, np.pi/2, num=n)
        k1 = d[0, 0]
        k2 = d[0, 1]
        k3 = d[0, 2]
        k4 = d[0, 3]
        rp = self.__apply_polynomial(a, k1, k2, k3, k4)
        kp = np.polyfit(rp, a, 4)
        kp1 = kp[3]
        kp2 = kp[2]
        kp3 = kp[1]
        kp4 = kp[0]

        a_rep = self.__apply_polynomial(rp, kp1, kp2, kp3, kp4)

        error_a = np.sum(np.abs(a-a_rep)) / n
        error_a_deg = error_a * 180 / np.pi

        if error_a_deg &gt; 1e-1:
            warnings.warn(&#34;WARNING: the inverse of the CameraFisheye distortion produces reprojection error &gt; 1e-2 &#34;
                          &#34;(i.e. higher than tenth of degree&#34;)

        return np.array([[kp1, kp2, kp3, kp4]])

    def undistort_image(self, img):
        if not self.is_distorted():
            return img
        if not self.__has_remaps():
            self.__compute_remaps()
        return cv.remap(img, self.mapX_to_und_16SC2, self.mapY_to_und_16SC2, interpolation=cv.INTER_LINEAR,
                        borderMode=cv.BORDER_CONSTANT)

    def undistort_points2d(self, points2d_dist_3xN):
        # This is a transfer from the distorted to the undistorted
        rays3d_dist_3xN = utils.inv(self.K_3x3).dot(points2d_dist_3xN)
        rays3d_und_3xN = self.undistort_rays3d(rays3d_dist_3xN)
        points2d_und_3xN = self.K_und_3x3.dot(rays3d_und_3xN)

        return points2d_und_3xN

    def distort_points2d(self, points2d_und_3xN):
        # This is a transfer from the undistorted domain to the distorted
        rays3d_und_3xN = utils.inv(self.K_und_3x3).dot(points2d_und_3xN)
        rays3d_dist_3xN = self.distort_rays3d(rays3d_und_3xN) # TODO: better to use self.project_points?
        points2d_dist_3xN = self.K_3x3.dot(rays3d_dist_3xN)

        return points2d_dist_3xN

    def is_distorted(self):
        return np.count_nonzero(self.d_1x4) &gt; 0

    def undistort_rays3d(self, rays3d_dist_3xN):
        &#34;&#34;&#34;
        This function undistort 3d rays according to the inverse polynomial function.
        :param rays3d_dist_3xN: 3d rays (connecting optical center and image plane using K)
        :return: undistorted rays as 3xN
        &#34;&#34;&#34;
        N = rays3d_dist_3xN.shape[1]
        if N == 0 or not self.is_distorted():
            rays3d_und_3xN = np.array([[]])
            return rays3d_und_3xN

        rays3d_und_3xN = np.zeros((3, N))
        for i in range(0, N):
            X = rays3d_dist_3xN[0, i]
            Y = rays3d_dist_3xN[1, i]
            rp = utils.norm([X, Y])
            a = self.__apply_polynomial(rp, self.d_inv_1x4[0, 0],
                                         self.d_inv_1x4[0, 1],
                                         self.d_inv_1x4[0, 2],
                                         self.d_inv_1x4[0, 3])
            r = math.tan(a)
            r_rp = np.float(r / rp)
            if rp &gt; 1e-8:
                rays3d_und_3xN[0, i] = X * r_rp
                rays3d_und_3xN[1, i] = Y * r_rp
                rays3d_und_3xN[2, i] = 1
            else:
                rays3d_und_3xN[0, i] = 0
                rays3d_und_3xN[1, i] = 0
                rays3d_und_3xN[2, i] = 1

        return rays3d_und_3xN

    def distort_rays3d(self, rays3d_3xN):
        &#34;&#34;&#34;
        This function distort 3d rays according to the distortion function.
        :param rays3d_3xN: 3d rays as 3xN arrays
        :return: distorted 3d rays as 3xN arrays after applying distortion function.
        &#34;&#34;&#34;
        N = rays3d_3xN.shape[1]
        if N == 0 or not self.is_distorted():
            rays3d_dist_3xN = np.array([[]])
            return rays3d_dist_3xN

        rays3d_dist_3xN = np.zeros((3, N))
        for i in range(0, N):
            X = rays3d_3xN[0, i]
            Y = rays3d_3xN[1, i]
            Z = rays3d_3xN[2, i]
            r = utils.norm([X, Y])
            a = math.atan2(r, Z)
            rp = self.__apply_polynomial(a, self.d_1x4[0, 0], self.d_1x4[0, 1], self.d_1x4[0, 2], self.d_1x4[0, 3])
            rp_r = np.float(rp/r)
            if r &gt; 1e-8:
                rays3d_dist_3xN[0, i] = X*rp_r
                rays3d_dist_3xN[1, i] = Y*rp_r
                rays3d_dist_3xN[2, i] = 1
            else:
                rays3d_dist_3xN[0, i] = 0
                rays3d_dist_3xN[1, i] = 0
                rays3d_dist_3xN[2, i] = 1

        return rays3d_dist_3xN

    def project_points3d(self, points3d_4xN, apply_distortion=True, remove_outside=False):
        &#34;&#34;&#34;
        This function projects 3d points in camera coordinate system using the angle-of-incidence projection model.
        Any 3D point in space P=(X,Y,Z,1)^T has a radius with respect to the optical axis Z
        r = ||X^2 + Y^2||
        The angle of incidence to the optical center is
        a = atan(r/Z)
        The angle of incidence then spans from 0 to pi/2
        The model of the lens relates the angle of incidence with the radius of the point in the image plane (in pixels):
        rp = k1*a + k2*a^2 + k3*a^3 + k4*a^4
        Then, the point in the image plane is recovered from rp as:
        p = (X*rp/r + w/2 + cx, Y*rp/r + h/2 + cy)

        If apply_distortion is True, the projection creates points in the distorted domain.
        If apply_distortion is False, the projection creates points in the undistorted domain (NOT IMPLEMENTED!).

        :param points3d_4xN: 3D points in camera coordinate system
        :param apply_distortion: boolean to obtain points in the distorted domain.
        :param remove_outside: filter out points that fall outside the limits of the image frame.
        :return: 2D points in image plane, as 3xN array, in hom. coordinates, and boolean array of valid
        &#34;&#34;&#34;
        # 0.- Pre-filter
        assert (points3d_4xN.ndim == 2)
        N = points3d_4xN.shape[1]
        if N == 0:
            return np.array([[]]), []

        # 1.- Select only those z &gt; 0 (in front of the camera)
        idx_in_front = points3d_4xN[2, :] &gt; 1e-8
        idx_valid = idx_in_front

        # 2.- Distort rays3d if distorted
        rays3d_3xN_filt = points3d_4xN[0:3, idx_valid]
        rays3d_3xN_filt = rays3d_3xN_filt[0:3, :] / rays3d_3xN_filt[2, :]  # so (x&#39;, y&#39;, 1), convenient for dist.
        rays3d_3xN = np.full([3, N], np.nan)
        rays3d_3xN[:, idx_valid] = rays3d_3xN_filt

        if apply_distortion:
            # Now distort (only non-nans)
            rays3d_3xN_filt = rays3d_3xN[:, idx_valid]
            rays3d_3xN_filt_dist = self.distort_rays3d(rays3d_3xN_filt)  # no nan should go into it


            # DEBUG
            #temp = self.undistort_rays3d(rays3d_3xN_filt_dist)
            #error = np.linalg.norm(rays3d_3xN_filt - temp)

            # Add nans
            rays3d_3xN = np.full([3, N], np.nan)
            rays3d_3xN[:, idx_valid] = rays3d_3xN_filt_dist

        # 3.- Project using calibration matrix
        if apply_distortion:
            points2d_3xN = self.K_3x3.dot(rays3d_3xN)
            if remove_outside:
                points2d_3xN, idx_valid = utils.filter_outside(points2d_3xN, self.img_size_dist, idx_valid)
        else:
            if not self.__has_remaps():
                self.__compute_remaps()
            points2d_3xN = self.K_und_3x3.dot(rays3d_3xN)
            if remove_outside:
                points2d_3xN, idx_valid = utils.filter_outside(points2d_3xN, self.img_size_undist, idx_valid)

        return points2d_3xN, idx_valid

    def init_undistort_rectify_map(self, K_und_3x3, img_size_undist):
        # Create maps
        w = img_size_undist[0]
        h = img_size_undist[1]
        map1 = np.zeros((h, w), dtype=np.float32)
        map2 = np.zeros((h, w), dtype=np.float32)

        # Loop over undistorted domain
        for i in range(0, h):
            # Read all pixel pos of this row
            points2d_und_3xN = np.array([np.linspace(0, w-1, num=w),
                                    i*np.ones(w),
                                    np.ones(w)])

            # Un-apply K_und to get the undistorted ray
            ray3d_und_3xN = utils.inv(K_und_3x3).dot(points2d_und_3xN)
            ray3d_und_3xN[0:3, :] = ray3d_und_3xN[0:3, :] / ray3d_und_3xN[2, :]
            ray3d_und_4xN = np.vstack((ray3d_und_3xN, np.ones(w)))

            # Project
            points2d_dist_3xN, idx_valid = self.project_points3d(ray3d_und_4xN)

            # Assign into map
            map1[i, :] = points2d_dist_3xN[0, :]
            map2[i, :] = points2d_dist_3xN[1, :]

        # Return the maps
        return map1, map2

    def estimate_new_camera_matrix_for_undistort_rectify(self, img_size_orig, balance, img_size_dst, fov_scale):
        balance = min(max(balance, 0.0), 1.0)
        w = img_size_orig[0]
        h = img_size_orig[1]
        romboid_points = np.array([[w/2, 0, 1],
                                   [w, h/2, 1],
                                   [w/2, h, 1],
                                   [0, h/2, 1]]).transpose()

        rays3d_und_3xN = self.undistort_rays3d(romboid_points)
        center_mass = cv.mean(rays3d_und_3xN)
        cn = center_mass
        aspect_ratio = 1.0

        # Find maxima
        minx = float(&#39;inf&#39;)
        miny = float(&#39;inf&#39;)
        maxx = -float(&#39;inf&#39;)
        maxy = -float(&#39;inf&#39;);
        for i in range(0, 4):
            miny = min(miny, rays3d_und_3xN[1, i])
            maxy = max(maxy, rays3d_und_3xN[1, i])
            minx = min(minx, rays3d_und_3xN[0, i])
            maxx = max(maxx, rays3d_und_3xN[0, i])

        f1 = w *0.5/(cn[0] - minx)
        f2 = w * 0.5 / (maxx - cn[0])
        f3 = h * 0.5 * aspect_ratio / (cn[1] - miny)
        f4 = h * 0.5 * aspect_ratio / (maxy - cn[1])

        fmin = min(f1, min(f2, min(f3, f4)))
        fmax = max(f1, max(f2, max(f3, f4)))

        f = balance * fmin + (1.0 - balance)*fmax
        if fov_scale &gt; 0:
            f *= (1.0/fov_scale)

        new_f = (f, f/aspect_ratio)
        new_c = (w*0.5 - cn[0] * f, ((h*aspect_ratio)*0.5 - cn[0] * f)/aspect_ratio)

        rx = img_size_dst[0] / img_size_orig[0]
        ry = img_size_dst[1] / img_size_orig[1]

        K_new = np.array([[new_f[0]*rx, 0, new_c[0]*rx],
                          [0, new_f[1]*ry, new_c[1]*ry],
                          [0, 0, 1]])

        return K_new

    def reproject_points2d(self, points2d_3xN, plane_cs, apply_undistorsion=True):
        N = points2d_3xN.shape[1]
        if N == 0:
            return np.array([[]]), []
        idx_valid = [True] * N

        # Undistort rays
        if apply_undistorsion:
            # First, get rays3d applying K^-1
            rays3d_dist_3xN = utils.inv(self.K_3x3).dot(points2d_3xN)
            rays3d_3xN = self.undistort_rays3d(rays3d_dist_3xN=rays3d_dist_3xN)
        else:
            # For those cases where this function is given undistorted points
            rays3d_dist_3xN = utils.inv(self.K_und_3x3).dot(points2d_3xN)
            rays3d_3xN = rays3d_dist_3xN

        # Use Plucker intersection line-plane
        # Create Plucker line using 2 points: origin of camera and origin of camera + ray
        P1 = np.vstack((0, 0, 0, 1))
        P2array = np.vstack((rays3d_3xN, np.ones((1, N))))
        # Plane equation in plucker coordinates (wrt to world)
        P = np.asarray(plane_cs).reshape(4, 1)
        # Line equation in plucker coordinates
        p3dNx4 = np.array([])
        count = 0
        for P2 in P2array.T:
            P2 = P2.reshape(4, 1)
            L = np.matmul(P1, np.transpose(P2)) - np.matmul(P2, np.transpose(P1))
            # Intersection is a 3D point
            p3Dlcs = np.matmul(L, P)
            if p3Dlcs[3][0] != 0:
                p3Dlcs /= p3Dlcs[3][0]  # homogeneous
            else:
                # This is an infinite point: return direction vector instead
                norm = np.linalg.norm(p3Dlcs[:3][0])
                p3Dlcs /= norm
                idx_valid[count] = False
            p3dNx4 = np.append(p3dNx4, p3Dlcs)
            count += 1
        p3dNx4 = p3dNx4.reshape(p3dNx4.shape[0] // 4, 4)
        p3d_4xN = np.transpose(p3dNx4)
        return p3d_4xN, idx_valid</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="vcd.scl.Camera" href="#vcd.scl.Camera">Camera</a></li>
<li><a title="vcd.scl.Sensor" href="#vcd.scl.Sensor">Sensor</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="vcd.scl.CameraFisheye.distort_points2d"><code class="name flex">
<span>def <span class="ident">distort_points2d</span></span>(<span>self, points2d_und_3xN)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def distort_points2d(self, points2d_und_3xN):
    # This is a transfer from the undistorted domain to the distorted
    rays3d_und_3xN = utils.inv(self.K_und_3x3).dot(points2d_und_3xN)
    rays3d_dist_3xN = self.distort_rays3d(rays3d_und_3xN) # TODO: better to use self.project_points?
    points2d_dist_3xN = self.K_3x3.dot(rays3d_dist_3xN)

    return points2d_dist_3xN</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraFisheye.distort_rays3d"><code class="name flex">
<span>def <span class="ident">distort_rays3d</span></span>(<span>self, rays3d_3xN)</span>
</code></dt>
<dd>
<div class="desc"><p>This function distort 3d rays according to the distortion function.
:param rays3d_3xN: 3d rays as 3xN arrays
:return: distorted 3d rays as 3xN arrays after applying distortion function.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def distort_rays3d(self, rays3d_3xN):
    &#34;&#34;&#34;
    This function distort 3d rays according to the distortion function.
    :param rays3d_3xN: 3d rays as 3xN arrays
    :return: distorted 3d rays as 3xN arrays after applying distortion function.
    &#34;&#34;&#34;
    N = rays3d_3xN.shape[1]
    if N == 0 or not self.is_distorted():
        rays3d_dist_3xN = np.array([[]])
        return rays3d_dist_3xN

    rays3d_dist_3xN = np.zeros((3, N))
    for i in range(0, N):
        X = rays3d_3xN[0, i]
        Y = rays3d_3xN[1, i]
        Z = rays3d_3xN[2, i]
        r = utils.norm([X, Y])
        a = math.atan2(r, Z)
        rp = self.__apply_polynomial(a, self.d_1x4[0, 0], self.d_1x4[0, 1], self.d_1x4[0, 2], self.d_1x4[0, 3])
        rp_r = np.float(rp/r)
        if r &gt; 1e-8:
            rays3d_dist_3xN[0, i] = X*rp_r
            rays3d_dist_3xN[1, i] = Y*rp_r
            rays3d_dist_3xN[2, i] = 1
        else:
            rays3d_dist_3xN[0, i] = 0
            rays3d_dist_3xN[1, i] = 0
            rays3d_dist_3xN[2, i] = 1

    return rays3d_dist_3xN</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraFisheye.estimate_new_camera_matrix_for_undistort_rectify"><code class="name flex">
<span>def <span class="ident">estimate_new_camera_matrix_for_undistort_rectify</span></span>(<span>self, img_size_orig, balance, img_size_dst, fov_scale)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def estimate_new_camera_matrix_for_undistort_rectify(self, img_size_orig, balance, img_size_dst, fov_scale):
    balance = min(max(balance, 0.0), 1.0)
    w = img_size_orig[0]
    h = img_size_orig[1]
    romboid_points = np.array([[w/2, 0, 1],
                               [w, h/2, 1],
                               [w/2, h, 1],
                               [0, h/2, 1]]).transpose()

    rays3d_und_3xN = self.undistort_rays3d(romboid_points)
    center_mass = cv.mean(rays3d_und_3xN)
    cn = center_mass
    aspect_ratio = 1.0

    # Find maxima
    minx = float(&#39;inf&#39;)
    miny = float(&#39;inf&#39;)
    maxx = -float(&#39;inf&#39;)
    maxy = -float(&#39;inf&#39;);
    for i in range(0, 4):
        miny = min(miny, rays3d_und_3xN[1, i])
        maxy = max(maxy, rays3d_und_3xN[1, i])
        minx = min(minx, rays3d_und_3xN[0, i])
        maxx = max(maxx, rays3d_und_3xN[0, i])

    f1 = w *0.5/(cn[0] - minx)
    f2 = w * 0.5 / (maxx - cn[0])
    f3 = h * 0.5 * aspect_ratio / (cn[1] - miny)
    f4 = h * 0.5 * aspect_ratio / (maxy - cn[1])

    fmin = min(f1, min(f2, min(f3, f4)))
    fmax = max(f1, max(f2, max(f3, f4)))

    f = balance * fmin + (1.0 - balance)*fmax
    if fov_scale &gt; 0:
        f *= (1.0/fov_scale)

    new_f = (f, f/aspect_ratio)
    new_c = (w*0.5 - cn[0] * f, ((h*aspect_ratio)*0.5 - cn[0] * f)/aspect_ratio)

    rx = img_size_dst[0] / img_size_orig[0]
    ry = img_size_dst[1] / img_size_orig[1]

    K_new = np.array([[new_f[0]*rx, 0, new_c[0]*rx],
                      [0, new_f[1]*ry, new_c[1]*ry],
                      [0, 0, 1]])

    return K_new</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraFisheye.init_undistort_rectify_map"><code class="name flex">
<span>def <span class="ident">init_undistort_rectify_map</span></span>(<span>self, K_und_3x3, img_size_undist)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def init_undistort_rectify_map(self, K_und_3x3, img_size_undist):
    # Create maps
    w = img_size_undist[0]
    h = img_size_undist[1]
    map1 = np.zeros((h, w), dtype=np.float32)
    map2 = np.zeros((h, w), dtype=np.float32)

    # Loop over undistorted domain
    for i in range(0, h):
        # Read all pixel pos of this row
        points2d_und_3xN = np.array([np.linspace(0, w-1, num=w),
                                i*np.ones(w),
                                np.ones(w)])

        # Un-apply K_und to get the undistorted ray
        ray3d_und_3xN = utils.inv(K_und_3x3).dot(points2d_und_3xN)
        ray3d_und_3xN[0:3, :] = ray3d_und_3xN[0:3, :] / ray3d_und_3xN[2, :]
        ray3d_und_4xN = np.vstack((ray3d_und_3xN, np.ones(w)))

        # Project
        points2d_dist_3xN, idx_valid = self.project_points3d(ray3d_und_4xN)

        # Assign into map
        map1[i, :] = points2d_dist_3xN[0, :]
        map2[i, :] = points2d_dist_3xN[1, :]

    # Return the maps
    return map1, map2</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraFisheye.is_distorted"><code class="name flex">
<span>def <span class="ident">is_distorted</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_distorted(self):
    return np.count_nonzero(self.d_1x4) &gt; 0</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraFisheye.project_points3d"><code class="name flex">
<span>def <span class="ident">project_points3d</span></span>(<span>self, points3d_4xN, apply_distortion=True, remove_outside=False)</span>
</code></dt>
<dd>
<div class="desc"><p>This function projects 3d points in camera coordinate system using the angle-of-incidence projection model.
Any 3D point in space P=(X,Y,Z,1)^T has a radius with respect to the optical axis Z
r = ||X^2 + Y^2||
The angle of incidence to the optical center is
a = atan(r/Z)
The angle of incidence then spans from 0 to pi/2
The model of the lens relates the angle of incidence with the radius of the point in the image plane (in pixels):
rp = k1<em>a + k2</em>a^2 + k3<em>a^3 + k4</em>a^4
Then, the point in the image plane is recovered from rp as:
p = (X<em>rp/r + w/2 + cx, Y</em>rp/r + h/2 + cy)</p>
<p>If apply_distortion is True, the projection creates points in the distorted domain.
If apply_distortion is False, the projection creates points in the undistorted domain (NOT IMPLEMENTED!).</p>
<p>:param points3d_4xN: 3D points in camera coordinate system
:param apply_distortion: boolean to obtain points in the distorted domain.
:param remove_outside: filter out points that fall outside the limits of the image frame.
:return: 2D points in image plane, as 3xN array, in hom. coordinates, and boolean array of valid</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def project_points3d(self, points3d_4xN, apply_distortion=True, remove_outside=False):
    &#34;&#34;&#34;
    This function projects 3d points in camera coordinate system using the angle-of-incidence projection model.
    Any 3D point in space P=(X,Y,Z,1)^T has a radius with respect to the optical axis Z
    r = ||X^2 + Y^2||
    The angle of incidence to the optical center is
    a = atan(r/Z)
    The angle of incidence then spans from 0 to pi/2
    The model of the lens relates the angle of incidence with the radius of the point in the image plane (in pixels):
    rp = k1*a + k2*a^2 + k3*a^3 + k4*a^4
    Then, the point in the image plane is recovered from rp as:
    p = (X*rp/r + w/2 + cx, Y*rp/r + h/2 + cy)

    If apply_distortion is True, the projection creates points in the distorted domain.
    If apply_distortion is False, the projection creates points in the undistorted domain (NOT IMPLEMENTED!).

    :param points3d_4xN: 3D points in camera coordinate system
    :param apply_distortion: boolean to obtain points in the distorted domain.
    :param remove_outside: filter out points that fall outside the limits of the image frame.
    :return: 2D points in image plane, as 3xN array, in hom. coordinates, and boolean array of valid
    &#34;&#34;&#34;
    # 0.- Pre-filter
    assert (points3d_4xN.ndim == 2)
    N = points3d_4xN.shape[1]
    if N == 0:
        return np.array([[]]), []

    # 1.- Select only those z &gt; 0 (in front of the camera)
    idx_in_front = points3d_4xN[2, :] &gt; 1e-8
    idx_valid = idx_in_front

    # 2.- Distort rays3d if distorted
    rays3d_3xN_filt = points3d_4xN[0:3, idx_valid]
    rays3d_3xN_filt = rays3d_3xN_filt[0:3, :] / rays3d_3xN_filt[2, :]  # so (x&#39;, y&#39;, 1), convenient for dist.
    rays3d_3xN = np.full([3, N], np.nan)
    rays3d_3xN[:, idx_valid] = rays3d_3xN_filt

    if apply_distortion:
        # Now distort (only non-nans)
        rays3d_3xN_filt = rays3d_3xN[:, idx_valid]
        rays3d_3xN_filt_dist = self.distort_rays3d(rays3d_3xN_filt)  # no nan should go into it


        # DEBUG
        #temp = self.undistort_rays3d(rays3d_3xN_filt_dist)
        #error = np.linalg.norm(rays3d_3xN_filt - temp)

        # Add nans
        rays3d_3xN = np.full([3, N], np.nan)
        rays3d_3xN[:, idx_valid] = rays3d_3xN_filt_dist

    # 3.- Project using calibration matrix
    if apply_distortion:
        points2d_3xN = self.K_3x3.dot(rays3d_3xN)
        if remove_outside:
            points2d_3xN, idx_valid = utils.filter_outside(points2d_3xN, self.img_size_dist, idx_valid)
    else:
        if not self.__has_remaps():
            self.__compute_remaps()
        points2d_3xN = self.K_und_3x3.dot(rays3d_3xN)
        if remove_outside:
            points2d_3xN, idx_valid = utils.filter_outside(points2d_3xN, self.img_size_undist, idx_valid)

    return points2d_3xN, idx_valid</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraFisheye.reproject_points2d"><code class="name flex">
<span>def <span class="ident">reproject_points2d</span></span>(<span>self, points2d_3xN, plane_cs, apply_undistorsion=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reproject_points2d(self, points2d_3xN, plane_cs, apply_undistorsion=True):
    N = points2d_3xN.shape[1]
    if N == 0:
        return np.array([[]]), []
    idx_valid = [True] * N

    # Undistort rays
    if apply_undistorsion:
        # First, get rays3d applying K^-1
        rays3d_dist_3xN = utils.inv(self.K_3x3).dot(points2d_3xN)
        rays3d_3xN = self.undistort_rays3d(rays3d_dist_3xN=rays3d_dist_3xN)
    else:
        # For those cases where this function is given undistorted points
        rays3d_dist_3xN = utils.inv(self.K_und_3x3).dot(points2d_3xN)
        rays3d_3xN = rays3d_dist_3xN

    # Use Plucker intersection line-plane
    # Create Plucker line using 2 points: origin of camera and origin of camera + ray
    P1 = np.vstack((0, 0, 0, 1))
    P2array = np.vstack((rays3d_3xN, np.ones((1, N))))
    # Plane equation in plucker coordinates (wrt to world)
    P = np.asarray(plane_cs).reshape(4, 1)
    # Line equation in plucker coordinates
    p3dNx4 = np.array([])
    count = 0
    for P2 in P2array.T:
        P2 = P2.reshape(4, 1)
        L = np.matmul(P1, np.transpose(P2)) - np.matmul(P2, np.transpose(P1))
        # Intersection is a 3D point
        p3Dlcs = np.matmul(L, P)
        if p3Dlcs[3][0] != 0:
            p3Dlcs /= p3Dlcs[3][0]  # homogeneous
        else:
            # This is an infinite point: return direction vector instead
            norm = np.linalg.norm(p3Dlcs[:3][0])
            p3Dlcs /= norm
            idx_valid[count] = False
        p3dNx4 = np.append(p3dNx4, p3Dlcs)
        count += 1
    p3dNx4 = p3dNx4.reshape(p3dNx4.shape[0] // 4, 4)
    p3d_4xN = np.transpose(p3dNx4)
    return p3d_4xN, idx_valid</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraFisheye.undistort_image"><code class="name flex">
<span>def <span class="ident">undistort_image</span></span>(<span>self, img)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def undistort_image(self, img):
    if not self.is_distorted():
        return img
    if not self.__has_remaps():
        self.__compute_remaps()
    return cv.remap(img, self.mapX_to_und_16SC2, self.mapY_to_und_16SC2, interpolation=cv.INTER_LINEAR,
                    borderMode=cv.BORDER_CONSTANT)</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraFisheye.undistort_points2d"><code class="name flex">
<span>def <span class="ident">undistort_points2d</span></span>(<span>self, points2d_dist_3xN)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def undistort_points2d(self, points2d_dist_3xN):
    # This is a transfer from the distorted to the undistorted
    rays3d_dist_3xN = utils.inv(self.K_3x3).dot(points2d_dist_3xN)
    rays3d_und_3xN = self.undistort_rays3d(rays3d_dist_3xN)
    points2d_und_3xN = self.K_und_3x3.dot(rays3d_und_3xN)

    return points2d_und_3xN</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraFisheye.undistort_rays3d"><code class="name flex">
<span>def <span class="ident">undistort_rays3d</span></span>(<span>self, rays3d_dist_3xN)</span>
</code></dt>
<dd>
<div class="desc"><p>This function undistort 3d rays according to the inverse polynomial function.
:param rays3d_dist_3xN: 3d rays (connecting optical center and image plane using K)
:return: undistorted rays as 3xN</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def undistort_rays3d(self, rays3d_dist_3xN):
    &#34;&#34;&#34;
    This function undistort 3d rays according to the inverse polynomial function.
    :param rays3d_dist_3xN: 3d rays (connecting optical center and image plane using K)
    :return: undistorted rays as 3xN
    &#34;&#34;&#34;
    N = rays3d_dist_3xN.shape[1]
    if N == 0 or not self.is_distorted():
        rays3d_und_3xN = np.array([[]])
        return rays3d_und_3xN

    rays3d_und_3xN = np.zeros((3, N))
    for i in range(0, N):
        X = rays3d_dist_3xN[0, i]
        Y = rays3d_dist_3xN[1, i]
        rp = utils.norm([X, Y])
        a = self.__apply_polynomial(rp, self.d_inv_1x4[0, 0],
                                     self.d_inv_1x4[0, 1],
                                     self.d_inv_1x4[0, 2],
                                     self.d_inv_1x4[0, 3])
        r = math.tan(a)
        r_rp = np.float(r / rp)
        if rp &gt; 1e-8:
            rays3d_und_3xN[0, i] = X * r_rp
            rays3d_und_3xN[1, i] = Y * r_rp
            rays3d_und_3xN[2, i] = 1
        else:
            rays3d_und_3xN[0, i] = 0
            rays3d_und_3xN[1, i] = 0
            rays3d_und_3xN[2, i] = 1

    return rays3d_und_3xN</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="vcd.scl.CameraPinhole"><code class="flex name class">
<span>class <span class="ident">CameraPinhole</span></span>
<span>(</span><span>camera_intrinsics, name, description, uri, compute_remaps=False)</span>
</code></dt>
<dd>
<div class="desc"><p>The Pinhole camera model defines a projection mechanism composed by two steps:</p>
<ul>
<li>Linear projection: using the camera_matrix (K)</li>
<li>Radial/Tangential/&hellip; distortion: using distortion coefficients</li>
</ul>
<p>If distortion has 4 coefficients, it is assumed to be "fisheye" type, as in:
<a href="https://docs.opencv.org/3.4/db/d58/group__calib3d__fisheye.html">https://docs.opencv.org/3.4/db/d58/group__calib3d__fisheye.html</a>
Otherwise (5 or more), it is assumed to be traditional "radial" distortion, as in:
<a href="https://docs.opencv.org/4.2.0/d9/d0c/group__calib3d.html">https://docs.opencv.org/4.2.0/d9/d0c/group__calib3d.html</a>
'</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CameraPinhole(Camera):
    &#34;&#34;&#34;
    The Pinhole camera model defines a projection mechanism composed by two steps:

    - Linear projection: using the camera_matrix (K)
    - Radial/Tangential/... distortion: using distortion coefficients

    If distortion has 4 coefficients, it is assumed to be &#34;fisheye&#34; type, as in:
    https://docs.opencv.org/3.4/db/d58/group__calib3d__fisheye.html
    Otherwise (5 or more), it is assumed to be traditional &#34;radial&#34; distortion, as in:
    https://docs.opencv.org/4.2.0/d9/d0c/group__calib3d.html
    &#39;&#34;&#34;&#34;
    def __init__(self, camera_intrinsics, name, description, uri, compute_remaps=False):
        self.K_3x4 = np.array(camera_intrinsics[&#39;camera_matrix_3x4&#39;]).reshape(3, 4)
        rows, cols, = self.K_3x4.shape
        assert (rows == 3 and cols == 4)
        self.K_3x3 = utils.fromCameraMatrix3x4toCameraMatrix3x3(self.K_3x4)
        d_list = camera_intrinsics[&#39;distortion_coeffs_1xN&#39;]
        self.d_1xN = np.array(d_list).reshape(1, len(d_list))

        self.is_fisheye = len(d_list) == 4

        self.r_limit = None
        if self.is_distorted() and not self.is_fisheye:
            self.r_limit = utils.get_distortion_radius(self.d_1xN)

        # Pre-compute undistortion maps (LUTs)
        self.img_size_dist = (camera_intrinsics[&#39;width_px&#39;], camera_intrinsics[&#39;height_px&#39;])
        self.img_size_undist = (camera_intrinsics[&#39;width_px&#39;], camera_intrinsics[&#39;height_px&#39;])

        if self.is_distorted():
            # TODO: Add img_size_undist to user-defined params
            if self.is_fisheye:
                self.K_und_3x3 = cv.fisheye.estimateNewCameraMatrixForUndistortRectify(self.K_3x3, self.d_1xN,
                                                                                       self.img_size_dist, np.eye(3),
                                                                                       balance=1,
                                                                                       new_size=self.img_size_undist, fov_scale=1)

                self.mapX_to_und_16SC2 = None
                self.mapY_to_und_16SC2 = None
                if compute_remaps:
                    # NOTE: using m1type=cv.CV_16SC2 leads to fixed point representation, which is reported to be faster, but
                    # less accurate. In addition, interpreting the maps in 16SC2 is not trivial because there are indices
                    # of interpolated values (see https://docs.opencv.org/3.1.0/da/d54/group__imgproc__transform.html#gab75ef31ce5cdfb5c44b6da5f3b908ea4)
                    print(&#34;CameraPinhole(fisheye): Compute remaps for undistortion...&#34;)
                    self.__compute_remaps()

            else:
                # alpha = 0.0 means NO black points in undistorted image
                # alpha = 1.0 means ALL distorted points inside limits of undistorted image
                aux = cv.getOptimalNewCameraMatrix(self.K_3x3, self.d_1xN, self.img_size_dist, alpha=0.0,
                                                              newImgSize=self.img_size_undist)
                self.K_und_3x3 = aux[0]
                self.mapX_to_und_16SC2 = None
                self.mapY_to_und_16SC2 = None
                if compute_remaps:
                    self.__compute_remaps()

        else:
            self.K_und_3x3 = self.K_3x3

        self.K_und_3x4 = utils.fromCameraMatrix3x3toCameraMatrix3x4(self.K_und_3x3)

        Camera.__init__(self, camera_intrinsics[&#39;width_px&#39;],
                        camera_intrinsics[&#39;height_px&#39;],
                        name, description, uri)

    def __has_remaps(self):
        if self.mapX_to_und_16SC2 is None or self.mapY_to_und_16SC2 is None:
            return False
        return True

    def __compute_remaps(self):
        start = time.time()
        self.mapX_to_und_16SC2, self.mapY_to_und_16SC2 = cv.initUndistortRectifyMap(self.K_3x3, self.d_1xN,
                                                                                    R=np.eye(3),
                                                                                    newCameraMatrix=self.K_und_3x3,
                                                                                    size=self.img_size_undist,
                                                                                    m1type=cv.CV_16SC2)
        end = time.time()
        print(&#34;CameraPinhole(radial): Compute remaps for undistortion... &#34;, end - start)

    def __test_undistortion(self, img, img_und):
        # Let&#39;s test if we project a 3D point into the distorted image
        # and into the undistorted image
        # And convert from one into another
        # Conclusions would be: we can work in any domain (distorted or undistorted), and
        # keep the ability to project and reproject 3D points

        # 1.- Create some points
        N = 100
        points3d_4xN = np.ones((3, N))
        points3d_4xN[0:3, :] = points3d_4xN[0:3, :]*np.random.random((3, N))*10

        # 2.- Project points into distorted image
        points2d_3xN_dist, idx_valid = self.project_points3d(points3d_4xN)
        points2d_3xN_dist = points2d_3xN_dist[:, idx_valid]

        # 3.- Draw into image
        for i in range(0, points2d_3xN_dist.shape[1]):
            cv.circle(img, (utils.round(points2d_3xN_dist[0, i]),
                            utils.round(points2d_3xN_dist[1, i])), 2, (255, 0, 0), -1)

        # 4.- Undistort these points
        points2d_3xN_dist_und = self.undistort_points2d(points2d_3xN_dist)

    def undistort_image(self, img):
        if not self.is_distorted():
            return img
        if not self.__has_remaps():
            self.__compute_remaps()
        # cv.remap works for both models cv. and cv.fisheye
        return cv.remap(img, self.mapX_to_und_16SC2, self.mapY_to_und_16SC2, interpolation=cv.INTER_LINEAR,
                        borderMode=cv.BORDER_CONSTANT)

    def get_rays3d(self, point2d_3xN, K_3x3):
        rays3d_3xN = np.matmul((np.linalg.inv(K_3x3)), point2d_3xN)
        rays3d_3xN /= np.linalg.norm(rays3d_3xN)
        #ray3d_4xN = np.vstack((ray, np.ones((1, point2d_3xN.shape[1]))))
        #return ray3d_4xN
        return rays3d_3xN

    def is_distorted(self):
        return np.count_nonzero(self.d_1xN) &gt; 0

    def distort_points2d(self, points2d_und_3xN):
        &#34;&#34;&#34;
        This is a function to project from undistorted to distorted images.
        :param points2d_und_3xN: undistorted points 3xN homogeneous coordinates
        :return: distorted points 3xN homogeneous coordinates
        &#34;&#34;&#34;
        rays3d_und_3xN = utils.inv(self.K_und_3x3).dot(points2d_und_3xN)
        rays3d_dist_3xN = self.distort_rays3d(rays3d_und_3xN)
        points2d_dist_3xN = self.K_3x3.dot(rays3d_dist_3xN)
        return points2d_dist_3xN

    def undistort_points2d(self, points2d_dist_3xN):
        &#34;&#34;&#34;
        This function provides a mechanism to transfer from the distorted domain to the undistorted domain.

        E.g.
        img_und = self.camera.undistort_image(_img)
        points2d_und_3xN = self.camera.undistort_points2d(points2d_3xN)
        rows, cols = points2d_und_3xN.shape
        for i in range(0, cols):
            cv.circle(img_und, (utils.round(points2d_und_3xN[0, i]), utils.round(points2d_und_3xN[1, i])),
                2, (255, 255, 255), -1)
        cv.namedWindow(&#39;undistorted-test&#39;, cv.WINDOW_NORMAL)
        cv.imshow(&#39;undistorted-test&#39;, img_und)
        :param points2d_3xN: array of 2d points in homogeneous coordiantes 3xN
        :return: array of undistorted 2d points in homogeneous coordinates 3xN
        &#34;&#34;&#34;
        N = points2d_dist_3xN.shape[1]
        if N &lt; 1 or not self.is_distorted():
            return points2d_dist_3xN

        # Change shape from (3, N) to (N, 1, 2) so we can use OpenCV, removing homogeneous coordinate
        temp1 = points2d_dist_3xN[0:2, :]
        temp2 = utils.from_MxN_to_OpenCV_Nx1xM(temp1)

        # Use OpenCV functions
        if self.is_fisheye:
            temp3 = cv.fisheye.undistortPoints(temp2, self.K_3x3, self.d_1xN)
        else:
            temp3 = cv.undistortPoints(temp2, self.K_3x3, self.d_1xN)

        # Reshape to (3, N)
        temp3.shape = (N, 2)
        points2d_und_3xN = np.vstack((temp3.T, np.ones((1, N))))

        # Map into undistorted domain by using K_3x3_und
        points2d_und_3xN = self.K_und_3x3.dot(points2d_und_3xN)

        test = False
        if test:
            points2d_dist_re_3xN = self.distort_points2d(points2d_und_3xN)
            error = np.linalg.norm(points2d_dist_re_3xN - points2d_dist_3xN)
            print(&#34;Undistortion error: &#34;, error)

        return points2d_und_3xN

    def distort_rays3d(self, rays3d_3xN):
        &#34;&#34;&#34;
        This function distort 3d rays according to the distortion function.
        :param rays3d_3xN: 3d rays as 3xN arrays
        :return: distorted 3d rays as 3xN arrays after applying distortion function.
        &#34;&#34;&#34;
        N = rays3d_3xN.shape[1]
        if N == 0 or not self.is_distorted():
            rays3d_dist_3xN = np.array([[]])
            return rays3d_dist_3xN

        # Normalize so last coordinate is 1
        rays3d_3xN[0:3, :] = rays3d_3xN[0:3, :] / rays3d_3xN[2, :]

        if self.is_fisheye:
            temp0 = rays3d_3xN[0:2, :]  # remove homogeneous coordinate
            temp1 = utils.from_MxN_to_OpenCV_Nx1xM(temp0)  # Change shape to (N, 1, 2)
            temp2 = cv.fisheye.distortPoints(temp1, np.eye(3), self.d_1xN)  # apply distortion using an identity K
            temp2.shape = (N, 2)  # reshape to 2xN
            rays3d_dist_3xN = np.vstack((temp2.T, np.ones((1, temp2.shape[0]))))  # add homog. row so it is 3xN
        else:
            # NOTE: there is no cv.distortPoints() function as in cv.fisheye.distortPoints()
            # It is though possible to distort points using OpenCV by using cv.projectPoints function
            # As we don&#39;t want to use K matrices here, let&#39;s use an eye, so the results are rays and not points
            aux = cv.projectPoints(objectPoints=rays3d_3xN,
                                   rvec=np.array([[[0., 0., 0.]]]),
                                   tvec=np.array([[[0., 0., 0.]]]),
                                   cameraMatrix=np.eye(3),
                                   distCoeffs=self.d_1xN)
            rays3d_dist_3xN = utils.from_OpenCV_Nx1xM_to_MxN(aux[0])
            rays3d_dist_3xN = np.vstack((rays3d_dist_3xN.transpose(), np.ones((1, N))))

        return rays3d_dist_3xN

    def project_points3d(self, points3d_4xN, apply_distortion=True, remove_outside=False):
        &#34;&#34;&#34;
        This function projects 3D points into 2D points using the camera projection.
        All coordinates as homogeneous coordinates, and all 3D elements expressed wrt the camera coordinate system.

        If apply_distortion is False, the projection produces points in the undistorted image.
        If apply_distortion is True, the distortion process (if any) is applied into the distorted image.

        First, the 3D points are understood as 3D rays.
        If distorted, the rays3D are distorted into distorted rays3D.

        The calibration matrix K_3x3 or K_3x3_und (according to apply_distortion) is applied to produce points.

        Points outside limits are removed if remove_outside is True.

        :param points3d_4xN: 3D points in camera cs, homogeneous coordinates
        :param apply_distortion: flag to determine whether to project into distorted or undistorted domain
        :param remove_outside: flag to remove points that fall outside the limits of the target image
        :return: 2D points in image plane, as 3xN array, in hom. coordinates, and boolean array of valid
        &#34;&#34;&#34;

        # 0.- Pre-filter
        assert (points3d_4xN.ndim == 2)
        N = points3d_4xN.shape[1]
        if N == 0:
            return np.array([[]]), []

        # 1.- Select only those z &gt; 0 (in front of the camera)
        idx_in_front = points3d_4xN[2, :] &gt; 1e-8
        idx_valid = idx_in_front

        # 2.- Distort rays3d if distorted
        rays3d_3xN_filt = points3d_4xN[0:3, idx_valid]
        rays3d_3xN_filt = rays3d_3xN_filt[0:3, :] / rays3d_3xN_filt[2, :]  # so (x&#39;, y&#39;, 1), convenient for dist.
        rays3d_3xN = np.full([3, N], np.nan)
        rays3d_3xN[:, idx_valid] = rays3d_3xN_filt

        if self.is_distorted():
            if not self.is_fisheye:
                if self.r_limit is not None:
                    for i in range(0, N):
                        if idx_valid[i]:  # ignore those already filtered
                            xp = rays3d_3xN[0, i] / rays3d_3xN[2, i]  # this is x&#39;=x/z as in opencv docs
                            yp = rays3d_3xN[1, i] / rays3d_3xN[2, i]  # this is y&#39;=y/z
                            r = np.sqrt(xp * xp + yp * yp)

                            if r &gt;= self.r_limit * 0.8:  # 0.8 to also remove very close to limit
                                idx_valid[i] = False
                                rays3d_3xN[:, i] = np.nan

            if apply_distortion:
                # Now distort (only non-nans)
                rays3d_3xN_filt = rays3d_3xN[:, idx_valid]
                rays3d_3xN_filt_dist = self.distort_rays3d(rays3d_3xN_filt) # no nan should go into it

                # Add nans
                rays3d_3xN = np.full([3, N], np.nan)
                rays3d_3xN[:, idx_valid] = rays3d_3xN_filt_dist

        # 3.- Project using calibration matrix
        if apply_distortion:
            points2d_3xN = self.K_3x3.dot(rays3d_3xN)
            if remove_outside:
                points2d_3xN, idx_valid = utils.filter_outside(points2d_3xN, self.img_size_dist, idx_valid)
        else:
            points2d_3xN = self.K_und_3x3.dot(rays3d_3xN)
            if remove_outside:
                points2d_3xN, idx_valid = utils.filter_outside(points2d_3xN, self.img_size_undist, idx_valid)

        return points2d_3xN, idx_valid

    def reproject_points2d(self, points2d_3xN, plane_cs, apply_undistorsion = True):
        &#34;&#34;&#34;
        This function takes 2D points in the (distorted) image and traces back a 3D ray from the camera optical axis
        through the point and gets the intersection with a defined world plane (in the form (a, b, c, d)).

        This function takes distortion into consideration, by first undistorting the 2D points, and then raycasting
        the 3D ray, free of distortion to apply Plücker formulation to obtain the intersection of a 3D line with
        a 3D plane.

        To manage tha case where the back-projection does not intersect the plane (which can happen for parallel set
        -ups of infinite points), the function returns an array of booleans that define the validity of the projection.

        :param points2D_3xN: array 2D points as 3XN array of homogeneous coordinates, representing points in the original
        image
        :param plane_cs: a plane expressed in general form (a, b, c, d) expressing a 3D plane in camera coordinate
        system
        :return: returns an array of 3D points (4xN array) in homogeneous coordinates, expressed in the camera
        coordinate systems, belonging to the world plane; and a 1xN array of booleans.
        &#34;&#34;&#34;
        # First, undistort point, so we can project back linear rays
        points2d_und_3xN = points2d_3xN
        if self.is_distorted() and apply_undistorsion:
            points2d_und_3xN = self.undistort_points2d(points2d_3xN)

        N = points2d_und_3xN.shape[1]
        if N == 0:
            return np.array([[]]), []
        idx_valid = [True] * N

        # Get ray 3D (expressed in camera coordinate system)
        rays3d_3xN = self.get_rays3d(points2d_und_3xN, self.K_und_3x3)

        # Use Plucker intersection line-plane
        # Create Plucker line using 2 points: origin of camera and origin of camera + ray
        P1 = np.vstack((0, 0, 0, 1))
        P2array = np.vstack((rays3d_3xN, np.ones((1, N))))
        # Plane equation in plucker coordinates (wrt to world)
        P = np.asarray(plane_cs).reshape(4, 1)
        # Line equation in plucker coordinates
        p3dNx4 = np.array([])
        count = 0
        for P2 in P2array.T:
            P2 = P2.reshape(4, 1)
            L = np.matmul(P1, np.transpose(P2)) - np.matmul(P2, np.transpose(P1))
            # Intersection is a 3D point
            p3Dlcs = np.matmul(L, P)
            if p3Dlcs[3][0] != 0:
                p3Dlcs /= p3Dlcs[3][0]  # homogeneous
            else:
                # This is an infinite point: return direction vector instead
                norm = np.linalg.norm(p3Dlcs[:3][0])
                p3Dlcs /= norm
                idx_valid[count] = False
            p3dNx4 = np.append(p3dNx4, p3Dlcs)
            count += 1
        p3dNx4 = p3dNx4.reshape(p3dNx4.shape[0] // 4, 4)
        p3d_4xN = np.transpose(p3dNx4)
        return p3d_4xN, idx_valid</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="vcd.scl.Camera" href="#vcd.scl.Camera">Camera</a></li>
<li><a title="vcd.scl.Sensor" href="#vcd.scl.Sensor">Sensor</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="vcd.scl.CameraPinhole.distort_points2d"><code class="name flex">
<span>def <span class="ident">distort_points2d</span></span>(<span>self, points2d_und_3xN)</span>
</code></dt>
<dd>
<div class="desc"><p>This is a function to project from undistorted to distorted images.
:param points2d_und_3xN: undistorted points 3xN homogeneous coordinates
:return: distorted points 3xN homogeneous coordinates</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def distort_points2d(self, points2d_und_3xN):
    &#34;&#34;&#34;
    This is a function to project from undistorted to distorted images.
    :param points2d_und_3xN: undistorted points 3xN homogeneous coordinates
    :return: distorted points 3xN homogeneous coordinates
    &#34;&#34;&#34;
    rays3d_und_3xN = utils.inv(self.K_und_3x3).dot(points2d_und_3xN)
    rays3d_dist_3xN = self.distort_rays3d(rays3d_und_3xN)
    points2d_dist_3xN = self.K_3x3.dot(rays3d_dist_3xN)
    return points2d_dist_3xN</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraPinhole.distort_rays3d"><code class="name flex">
<span>def <span class="ident">distort_rays3d</span></span>(<span>self, rays3d_3xN)</span>
</code></dt>
<dd>
<div class="desc"><p>This function distort 3d rays according to the distortion function.
:param rays3d_3xN: 3d rays as 3xN arrays
:return: distorted 3d rays as 3xN arrays after applying distortion function.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def distort_rays3d(self, rays3d_3xN):
    &#34;&#34;&#34;
    This function distort 3d rays according to the distortion function.
    :param rays3d_3xN: 3d rays as 3xN arrays
    :return: distorted 3d rays as 3xN arrays after applying distortion function.
    &#34;&#34;&#34;
    N = rays3d_3xN.shape[1]
    if N == 0 or not self.is_distorted():
        rays3d_dist_3xN = np.array([[]])
        return rays3d_dist_3xN

    # Normalize so last coordinate is 1
    rays3d_3xN[0:3, :] = rays3d_3xN[0:3, :] / rays3d_3xN[2, :]

    if self.is_fisheye:
        temp0 = rays3d_3xN[0:2, :]  # remove homogeneous coordinate
        temp1 = utils.from_MxN_to_OpenCV_Nx1xM(temp0)  # Change shape to (N, 1, 2)
        temp2 = cv.fisheye.distortPoints(temp1, np.eye(3), self.d_1xN)  # apply distortion using an identity K
        temp2.shape = (N, 2)  # reshape to 2xN
        rays3d_dist_3xN = np.vstack((temp2.T, np.ones((1, temp2.shape[0]))))  # add homog. row so it is 3xN
    else:
        # NOTE: there is no cv.distortPoints() function as in cv.fisheye.distortPoints()
        # It is though possible to distort points using OpenCV by using cv.projectPoints function
        # As we don&#39;t want to use K matrices here, let&#39;s use an eye, so the results are rays and not points
        aux = cv.projectPoints(objectPoints=rays3d_3xN,
                               rvec=np.array([[[0., 0., 0.]]]),
                               tvec=np.array([[[0., 0., 0.]]]),
                               cameraMatrix=np.eye(3),
                               distCoeffs=self.d_1xN)
        rays3d_dist_3xN = utils.from_OpenCV_Nx1xM_to_MxN(aux[0])
        rays3d_dist_3xN = np.vstack((rays3d_dist_3xN.transpose(), np.ones((1, N))))

    return rays3d_dist_3xN</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraPinhole.get_rays3d"><code class="name flex">
<span>def <span class="ident">get_rays3d</span></span>(<span>self, point2d_3xN, K_3x3)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_rays3d(self, point2d_3xN, K_3x3):
    rays3d_3xN = np.matmul((np.linalg.inv(K_3x3)), point2d_3xN)
    rays3d_3xN /= np.linalg.norm(rays3d_3xN)
    #ray3d_4xN = np.vstack((ray, np.ones((1, point2d_3xN.shape[1]))))
    #return ray3d_4xN
    return rays3d_3xN</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraPinhole.is_distorted"><code class="name flex">
<span>def <span class="ident">is_distorted</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_distorted(self):
    return np.count_nonzero(self.d_1xN) &gt; 0</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraPinhole.project_points3d"><code class="name flex">
<span>def <span class="ident">project_points3d</span></span>(<span>self, points3d_4xN, apply_distortion=True, remove_outside=False)</span>
</code></dt>
<dd>
<div class="desc"><p>This function projects 3D points into 2D points using the camera projection.
All coordinates as homogeneous coordinates, and all 3D elements expressed wrt the camera coordinate system.</p>
<p>If apply_distortion is False, the projection produces points in the undistorted image.
If apply_distortion is True, the distortion process (if any) is applied into the distorted image.</p>
<p>First, the 3D points are understood as 3D rays.
If distorted, the rays3D are distorted into distorted rays3D.</p>
<p>The calibration matrix K_3x3 or K_3x3_und (according to apply_distortion) is applied to produce points.</p>
<p>Points outside limits are removed if remove_outside is True.</p>
<p>:param points3d_4xN: 3D points in camera cs, homogeneous coordinates
:param apply_distortion: flag to determine whether to project into distorted or undistorted domain
:param remove_outside: flag to remove points that fall outside the limits of the target image
:return: 2D points in image plane, as 3xN array, in hom. coordinates, and boolean array of valid</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def project_points3d(self, points3d_4xN, apply_distortion=True, remove_outside=False):
    &#34;&#34;&#34;
    This function projects 3D points into 2D points using the camera projection.
    All coordinates as homogeneous coordinates, and all 3D elements expressed wrt the camera coordinate system.

    If apply_distortion is False, the projection produces points in the undistorted image.
    If apply_distortion is True, the distortion process (if any) is applied into the distorted image.

    First, the 3D points are understood as 3D rays.
    If distorted, the rays3D are distorted into distorted rays3D.

    The calibration matrix K_3x3 or K_3x3_und (according to apply_distortion) is applied to produce points.

    Points outside limits are removed if remove_outside is True.

    :param points3d_4xN: 3D points in camera cs, homogeneous coordinates
    :param apply_distortion: flag to determine whether to project into distorted or undistorted domain
    :param remove_outside: flag to remove points that fall outside the limits of the target image
    :return: 2D points in image plane, as 3xN array, in hom. coordinates, and boolean array of valid
    &#34;&#34;&#34;

    # 0.- Pre-filter
    assert (points3d_4xN.ndim == 2)
    N = points3d_4xN.shape[1]
    if N == 0:
        return np.array([[]]), []

    # 1.- Select only those z &gt; 0 (in front of the camera)
    idx_in_front = points3d_4xN[2, :] &gt; 1e-8
    idx_valid = idx_in_front

    # 2.- Distort rays3d if distorted
    rays3d_3xN_filt = points3d_4xN[0:3, idx_valid]
    rays3d_3xN_filt = rays3d_3xN_filt[0:3, :] / rays3d_3xN_filt[2, :]  # so (x&#39;, y&#39;, 1), convenient for dist.
    rays3d_3xN = np.full([3, N], np.nan)
    rays3d_3xN[:, idx_valid] = rays3d_3xN_filt

    if self.is_distorted():
        if not self.is_fisheye:
            if self.r_limit is not None:
                for i in range(0, N):
                    if idx_valid[i]:  # ignore those already filtered
                        xp = rays3d_3xN[0, i] / rays3d_3xN[2, i]  # this is x&#39;=x/z as in opencv docs
                        yp = rays3d_3xN[1, i] / rays3d_3xN[2, i]  # this is y&#39;=y/z
                        r = np.sqrt(xp * xp + yp * yp)

                        if r &gt;= self.r_limit * 0.8:  # 0.8 to also remove very close to limit
                            idx_valid[i] = False
                            rays3d_3xN[:, i] = np.nan

        if apply_distortion:
            # Now distort (only non-nans)
            rays3d_3xN_filt = rays3d_3xN[:, idx_valid]
            rays3d_3xN_filt_dist = self.distort_rays3d(rays3d_3xN_filt) # no nan should go into it

            # Add nans
            rays3d_3xN = np.full([3, N], np.nan)
            rays3d_3xN[:, idx_valid] = rays3d_3xN_filt_dist

    # 3.- Project using calibration matrix
    if apply_distortion:
        points2d_3xN = self.K_3x3.dot(rays3d_3xN)
        if remove_outside:
            points2d_3xN, idx_valid = utils.filter_outside(points2d_3xN, self.img_size_dist, idx_valid)
    else:
        points2d_3xN = self.K_und_3x3.dot(rays3d_3xN)
        if remove_outside:
            points2d_3xN, idx_valid = utils.filter_outside(points2d_3xN, self.img_size_undist, idx_valid)

    return points2d_3xN, idx_valid</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraPinhole.reproject_points2d"><code class="name flex">
<span>def <span class="ident">reproject_points2d</span></span>(<span>self, points2d_3xN, plane_cs, apply_undistorsion=True)</span>
</code></dt>
<dd>
<div class="desc"><p>This function takes 2D points in the (distorted) image and traces back a 3D ray from the camera optical axis
through the point and gets the intersection with a defined world plane (in the form (a, b, c, d)).</p>
<p>This function takes distortion into consideration, by first undistorting the 2D points, and then raycasting
the 3D ray, free of distortion to apply Plücker formulation to obtain the intersection of a 3D line with
a 3D plane.</p>
<p>To manage tha case where the back-projection does not intersect the plane (which can happen for parallel set
-ups of infinite points), the function returns an array of booleans that define the validity of the projection.</p>
<p>:param points2D_3xN: array 2D points as 3XN array of homogeneous coordinates, representing points in the original
image
:param plane_cs: a plane expressed in general form (a, b, c, d) expressing a 3D plane in camera coordinate
system
:return: returns an array of 3D points (4xN array) in homogeneous coordinates, expressed in the camera
coordinate systems, belonging to the world plane; and a 1xN array of booleans.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reproject_points2d(self, points2d_3xN, plane_cs, apply_undistorsion = True):
    &#34;&#34;&#34;
    This function takes 2D points in the (distorted) image and traces back a 3D ray from the camera optical axis
    through the point and gets the intersection with a defined world plane (in the form (a, b, c, d)).

    This function takes distortion into consideration, by first undistorting the 2D points, and then raycasting
    the 3D ray, free of distortion to apply Plücker formulation to obtain the intersection of a 3D line with
    a 3D plane.

    To manage tha case where the back-projection does not intersect the plane (which can happen for parallel set
    -ups of infinite points), the function returns an array of booleans that define the validity of the projection.

    :param points2D_3xN: array 2D points as 3XN array of homogeneous coordinates, representing points in the original
    image
    :param plane_cs: a plane expressed in general form (a, b, c, d) expressing a 3D plane in camera coordinate
    system
    :return: returns an array of 3D points (4xN array) in homogeneous coordinates, expressed in the camera
    coordinate systems, belonging to the world plane; and a 1xN array of booleans.
    &#34;&#34;&#34;
    # First, undistort point, so we can project back linear rays
    points2d_und_3xN = points2d_3xN
    if self.is_distorted() and apply_undistorsion:
        points2d_und_3xN = self.undistort_points2d(points2d_3xN)

    N = points2d_und_3xN.shape[1]
    if N == 0:
        return np.array([[]]), []
    idx_valid = [True] * N

    # Get ray 3D (expressed in camera coordinate system)
    rays3d_3xN = self.get_rays3d(points2d_und_3xN, self.K_und_3x3)

    # Use Plucker intersection line-plane
    # Create Plucker line using 2 points: origin of camera and origin of camera + ray
    P1 = np.vstack((0, 0, 0, 1))
    P2array = np.vstack((rays3d_3xN, np.ones((1, N))))
    # Plane equation in plucker coordinates (wrt to world)
    P = np.asarray(plane_cs).reshape(4, 1)
    # Line equation in plucker coordinates
    p3dNx4 = np.array([])
    count = 0
    for P2 in P2array.T:
        P2 = P2.reshape(4, 1)
        L = np.matmul(P1, np.transpose(P2)) - np.matmul(P2, np.transpose(P1))
        # Intersection is a 3D point
        p3Dlcs = np.matmul(L, P)
        if p3Dlcs[3][0] != 0:
            p3Dlcs /= p3Dlcs[3][0]  # homogeneous
        else:
            # This is an infinite point: return direction vector instead
            norm = np.linalg.norm(p3Dlcs[:3][0])
            p3Dlcs /= norm
            idx_valid[count] = False
        p3dNx4 = np.append(p3dNx4, p3Dlcs)
        count += 1
    p3dNx4 = p3dNx4.reshape(p3dNx4.shape[0] // 4, 4)
    p3d_4xN = np.transpose(p3dNx4)
    return p3d_4xN, idx_valid</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraPinhole.undistort_image"><code class="name flex">
<span>def <span class="ident">undistort_image</span></span>(<span>self, img)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def undistort_image(self, img):
    if not self.is_distorted():
        return img
    if not self.__has_remaps():
        self.__compute_remaps()
    # cv.remap works for both models cv. and cv.fisheye
    return cv.remap(img, self.mapX_to_und_16SC2, self.mapY_to_und_16SC2, interpolation=cv.INTER_LINEAR,
                    borderMode=cv.BORDER_CONSTANT)</code></pre>
</details>
</dd>
<dt id="vcd.scl.CameraPinhole.undistort_points2d"><code class="name flex">
<span>def <span class="ident">undistort_points2d</span></span>(<span>self, points2d_dist_3xN)</span>
</code></dt>
<dd>
<div class="desc"><p>This function provides a mechanism to transfer from the distorted domain to the undistorted domain.</p>
<p>E.g.
img_und = self.camera.undistort_image(_img)
points2d_und_3xN = self.camera.undistort_points2d(points2d_3xN)
rows, cols = points2d_und_3xN.shape
for i in range(0, cols):
cv.circle(img_und, (utils.round(points2d_und_3xN[0, i]), utils.round(points2d_und_3xN[1, i])),
2, (255, 255, 255), -1)
cv.namedWindow('undistorted-test', cv.WINDOW_NORMAL)
cv.imshow('undistorted-test', img_und)
:param points2d_3xN: array of 2d points in homogeneous coordiantes 3xN
:return: array of undistorted 2d points in homogeneous coordinates 3xN</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def undistort_points2d(self, points2d_dist_3xN):
    &#34;&#34;&#34;
    This function provides a mechanism to transfer from the distorted domain to the undistorted domain.

    E.g.
    img_und = self.camera.undistort_image(_img)
    points2d_und_3xN = self.camera.undistort_points2d(points2d_3xN)
    rows, cols = points2d_und_3xN.shape
    for i in range(0, cols):
        cv.circle(img_und, (utils.round(points2d_und_3xN[0, i]), utils.round(points2d_und_3xN[1, i])),
            2, (255, 255, 255), -1)
    cv.namedWindow(&#39;undistorted-test&#39;, cv.WINDOW_NORMAL)
    cv.imshow(&#39;undistorted-test&#39;, img_und)
    :param points2d_3xN: array of 2d points in homogeneous coordiantes 3xN
    :return: array of undistorted 2d points in homogeneous coordinates 3xN
    &#34;&#34;&#34;
    N = points2d_dist_3xN.shape[1]
    if N &lt; 1 or not self.is_distorted():
        return points2d_dist_3xN

    # Change shape from (3, N) to (N, 1, 2) so we can use OpenCV, removing homogeneous coordinate
    temp1 = points2d_dist_3xN[0:2, :]
    temp2 = utils.from_MxN_to_OpenCV_Nx1xM(temp1)

    # Use OpenCV functions
    if self.is_fisheye:
        temp3 = cv.fisheye.undistortPoints(temp2, self.K_3x3, self.d_1xN)
    else:
        temp3 = cv.undistortPoints(temp2, self.K_3x3, self.d_1xN)

    # Reshape to (3, N)
    temp3.shape = (N, 2)
    points2d_und_3xN = np.vstack((temp3.T, np.ones((1, N))))

    # Map into undistorted domain by using K_3x3_und
    points2d_und_3xN = self.K_und_3x3.dot(points2d_und_3xN)

    test = False
    if test:
        points2d_dist_re_3xN = self.distort_points2d(points2d_und_3xN)
        error = np.linalg.norm(points2d_dist_re_3xN - points2d_dist_3xN)
        print(&#34;Undistortion error: &#34;, error)

    return points2d_und_3xN</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="vcd.scl.Edge"><code class="flex name class">
<span>class <span class="ident">Edge</span></span>
<span>(</span><span>start, end, cost)</span>
</code></dt>
<dd>
<div class="desc"><p>Edge(start, end, cost)</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.tuple</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="vcd.scl.Edge.cost"><code class="name">var <span class="ident">cost</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 2</p></div>
</dd>
<dt id="vcd.scl.Edge.end"><code class="name">var <span class="ident">end</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 1</p></div>
</dd>
<dt id="vcd.scl.Edge.start"><code class="name">var <span class="ident">start</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 0</p></div>
</dd>
</dl>
</dd>
<dt id="vcd.scl.Graph"><code class="flex name class">
<span>class <span class="ident">Graph</span></span>
<span>(</span><span>edges)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Graph:
    def __init__(self, edges):
        # let&#39;s check that the data is right
        wrong_edges = [i for i in edges if len(i) not in [2, 3]]
        if wrong_edges:
            raise ValueError(&#39;Wrong edges data: {}&#39;.format(wrong_edges))

        self.edges = [make_edge(*edge) for edge in edges]

    @property
    def vertices(self):
        return set(
            sum(
                ([edge.start, edge.end] for edge in self.edges), []
            )
        )

    @staticmethod
    def get_node_pairs(n1, n2, both_ends=True):
        if both_ends:
            node_pairs = [[n1, n2], [n2, n1]]
        else:
            node_pairs = [[n1, n2]]
        return node_pairs

    def remove_edge(self, n1, n2, both_ends=True):
        node_pairs = self.get_node_pairs(n1, n2, both_ends)
        edges = self.edges[:]
        for edge in edges:
            if [edge.start, edge.end] in node_pairs:
                self.edges.remove(edge)

    def add_edge(self, n1, n2, cost=1, both_ends=True):
        node_pairs = self.get_node_pairs(n1, n2, both_ends)
        for edge in self.edges:
            if [edge.start, edge.end] in node_pairs:
                return ValueError(&#39;Edge {} {} already exists&#39;.format(n1, n2))

        self.edges.append(Edge(start=n1, end=n2, cost=cost))
        if both_ends:
            self.edges.append(Edge(start=n2, end=n1, cost=cost))

    @property
    def neighbours(self):
        neighbours = {vertex: set() for vertex in self.vertices}
        for edge in self.edges:
            neighbours[edge.start].add((edge.end, edge.cost))

        return neighbours

    def dijkstra(self, source, dest):
        assert source in self.vertices, &#39;Such source node doesn\&#39;t exist&#39;
        distances = {vertex: inf for vertex in self.vertices}
        previous_vertices = {
            vertex: None for vertex in self.vertices
        }
        distances[source] = 0
        vertices = self.vertices.copy()

        while vertices:
            current_vertex = min(
                vertices, key=lambda vertex: distances[vertex])
            vertices.remove(current_vertex)
            if distances[current_vertex] == inf:
                break
            for neighbour, cost in self.neighbours[current_vertex]:
                alternative_route = distances[current_vertex] + cost
                if alternative_route &lt; distances[neighbour]:
                    distances[neighbour] = alternative_route
                    previous_vertices[neighbour] = current_vertex

        path, current_vertex = deque(), dest
        while previous_vertices[current_vertex] is not None:
            path.appendleft(current_vertex)
            current_vertex = previous_vertices[current_vertex]
        if path:
            path.appendleft(current_vertex)
        return path</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="vcd.scl.Graph.get_node_pairs"><code class="name flex">
<span>def <span class="ident">get_node_pairs</span></span>(<span>n1, n2, both_ends=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def get_node_pairs(n1, n2, both_ends=True):
    if both_ends:
        node_pairs = [[n1, n2], [n2, n1]]
    else:
        node_pairs = [[n1, n2]]
    return node_pairs</code></pre>
</details>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="vcd.scl.Graph.neighbours"><code class="name">var <span class="ident">neighbours</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def neighbours(self):
    neighbours = {vertex: set() for vertex in self.vertices}
    for edge in self.edges:
        neighbours[edge.start].add((edge.end, edge.cost))

    return neighbours</code></pre>
</details>
</dd>
<dt id="vcd.scl.Graph.vertices"><code class="name">var <span class="ident">vertices</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def vertices(self):
    return set(
        sum(
            ([edge.start, edge.end] for edge in self.edges), []
        )
    )</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="vcd.scl.Graph.add_edge"><code class="name flex">
<span>def <span class="ident">add_edge</span></span>(<span>self, n1, n2, cost=1, both_ends=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_edge(self, n1, n2, cost=1, both_ends=True):
    node_pairs = self.get_node_pairs(n1, n2, both_ends)
    for edge in self.edges:
        if [edge.start, edge.end] in node_pairs:
            return ValueError(&#39;Edge {} {} already exists&#39;.format(n1, n2))

    self.edges.append(Edge(start=n1, end=n2, cost=cost))
    if both_ends:
        self.edges.append(Edge(start=n2, end=n1, cost=cost))</code></pre>
</details>
</dd>
<dt id="vcd.scl.Graph.dijkstra"><code class="name flex">
<span>def <span class="ident">dijkstra</span></span>(<span>self, source, dest)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dijkstra(self, source, dest):
    assert source in self.vertices, &#39;Such source node doesn\&#39;t exist&#39;
    distances = {vertex: inf for vertex in self.vertices}
    previous_vertices = {
        vertex: None for vertex in self.vertices
    }
    distances[source] = 0
    vertices = self.vertices.copy()

    while vertices:
        current_vertex = min(
            vertices, key=lambda vertex: distances[vertex])
        vertices.remove(current_vertex)
        if distances[current_vertex] == inf:
            break
        for neighbour, cost in self.neighbours[current_vertex]:
            alternative_route = distances[current_vertex] + cost
            if alternative_route &lt; distances[neighbour]:
                distances[neighbour] = alternative_route
                previous_vertices[neighbour] = current_vertex

    path, current_vertex = deque(), dest
    while previous_vertices[current_vertex] is not None:
        path.appendleft(current_vertex)
        current_vertex = previous_vertices[current_vertex]
    if path:
        path.appendleft(current_vertex)
    return path</code></pre>
</details>
</dd>
<dt id="vcd.scl.Graph.remove_edge"><code class="name flex">
<span>def <span class="ident">remove_edge</span></span>(<span>self, n1, n2, both_ends=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_edge(self, n1, n2, both_ends=True):
    node_pairs = self.get_node_pairs(n1, n2, both_ends)
    edges = self.edges[:]
    for edge in edges:
        if [edge.start, edge.end] in node_pairs:
            self.edges.remove(edge)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="vcd.scl.Scene"><code class="flex name class">
<span>class <span class="ident">Scene</span></span>
<span>(</span><span>vcd)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Scene:
    def __init__(self, vcd):
        self.vcd = vcd
        self.cameras = dict()

    def camera_roi_z0(self, camera_name, cs, frameNum):
        &#34;&#34;&#34;
        This function computes the region of the image which maps into the reference (cs) Z=0 plane
        by checking whether the re-projected point lies in front or behind the camera
        :param cam_name: camera name
        :param frameNum: frame num
        :return: polygon 2D
        &#34;&#34;&#34;
        # Working on undistorted coordinates
        hline, points = self.compute_horizon_line(camera_name=camera_name, cs=cs, frameNum=frameNum)
        cam = self.get_camera(camera_name=camera_name, frameNum=frameNum)
        width = cam.img_size_undist[0]
        height = cam.img_size_undist[1]

        # Create 2 contours going through the limits of the image and using points
        # Then check which of them contains points which are projected in Z&gt;0 in camera coordinate system
        polygon = []
        if len(points) == 0:
            # So, the line at the infinite is NOT inside the limits of the image
            # Let&#39;s then check if any point inside the image produces a Z&gt;0 (if not, this camera is pointing to the sky)
            point2d_dist_3x1 = np.array([[width / 2, height / 2, 1]]).transpose()

            # Reproject into self.coordinate_system Z=0 plane
            point3d_4x1, valid = self.reproject_points2d_3xN(points2d_3xN=point2d_dist_3x1, plane=(0, 0, 1, 0),
                                                             cs_cam=camera_name, cs_dst=cs, frameNum=frameNum,
                                                             apply_undistorsion=False)
            # Transform back to camera coordinate system
            point3d_4x1 = self.transform_points3d_4xN(points3d_4xN=point3d_4x1, cs_src=cs, cs_dst=camera_name,
                                                      frameNum=frameNum)
            in_front = point3d_4x1[2, 0] &gt; 0
            if in_front:
                polygon.append((0, 0))
                polygon.append((width - 1, 0))
                polygon.append((width - 1, height - 1))
                polygon.append((0, height - 1))

                return polygon
        else:
            # Ok, so the horizon line is INSIDE the limits of the undistorted domain
            # There are 6 possible configurations
            points_code = []
            U = None
            L = None
            R = None
            B = None
            for idx, point in enumerate(points):
                if point[1] == 0:  # So points[0] is U
                    points_code.append(&#39;U&#39;)
                    U = point
                elif point[0] == width:
                    points_code.append(&#39;R&#39;)
                    R = point
                elif point[1] == height:
                    points_code.append(&#39;B&#39;)
                    B = point
                else:
                    points_code.append(&#39;L&#39;)
                    L = point
            UL = (0, 0)
            UR = (width - 1, 0)
            BR = (width - 1, height - 1)
            BL = (0, height - 1)

            polygon_A = []
            polygon_B = []
            if &#39;U&#39; in points_code and &#39;L&#39; in points_code:
                # Case 0: LU
                polygon_A.append(UL)
                polygon_A.append(U)
                polygon_A.append(L)
                polygon_A.append(U)
                polygon_B.append(UR)
                polygon_B.append(BR)
                polygon_B.append(BL)
                polygon_B.append(L)
            elif &#39;U&#39; in points_code and &#39;B&#39; in points_code:
                # Case 1: BU
                polygon_A.append(UL)
                polygon_A.append(U)
                polygon_A.append(B)
                polygon_A.append(BL)
                polygon_B.append(U)
                polygon_B.append(UR)
                polygon_B.append(BR)
                polygon_B.append(B)
            elif &#39;U&#39; in points_code and &#39;R&#39; in points_code:
                # Case 2: RU
                polygon_A.append(U)
                polygon_A.append(UR)
                polygon_A.append(R)
                polygon_B.append(UL)
                polygon_B.append(U)
                polygon_B.append(R)
                polygon_B.append(BR)
                polygon_B.append(BL)
            elif &#39;L&#39; in points_code and &#39;B&#39; in points_code:
                # Case 3: LB
                polygon_A.append(L)
                polygon_A.append(B)
                polygon_A.append(BL)
                polygon_B.append(UL)
                polygon_B.append(UR)
                polygon_B.append(BR)
                polygon_B.append(B)
                polygon_B.append(L)
            elif &#39;L&#39; in points_code and &#39;R&#39; in points_code:
                # Case 4: LR
                polygon_A.append(UL)
                polygon_A.append(UR)
                polygon_A.append(R)
                polygon_A.append(L)
                polygon_B.append(L)
                polygon_B.append(R)
                polygon_B.append(BR)
                polygon_B.append(BL)
            else:
                # Case 5: BR
                polygon_A.append(B)
                polygon_A.append(R)
                polygon_A.append(BR)
                polygon_B.append(UL)
                polygon_B.append(UR)
                polygon_B.append(R)
                polygon_B.append(B)
                polygon_B.append(BR)

            # Now test whether polygon or polygon_other contain points which project to z&gt;0 camera
            point_A = (sum(x for x, y in polygon_A), sum(y for x, y in polygon_A))
            point_A = (point_A[0]/len(polygon_A), point_A[1]/len(polygon_A))

            point_B = (sum(x for x, y in polygon_B), sum(y for x, y in polygon_B))
            point_B = (point_B[0] / len(polygon_B), point_B[1] / len(polygon_B))

            # Reproject into self.coordinate_system Z=0 plane
            point_A_3x1 = np.array([[point_A[0], point_A[1], 1]]).transpose()
            point_A_3d_4x1, valid = self.reproject_points2d_3xN(points2d_3xN=point_A_3x1, plane=(0, 0, 1, 0),
                                                                cs_cam=camera_name, cs_dst=cs, frameNum=frameNum,
                                                                apply_undistorsion=False)
            # Transform back to camera coordinate system
            point_A_3d_4x1 = self.transform_points3d_4xN(points3d_4xN=point_A_3d_4x1, cs_src=cs, cs_dst=camera_name,
                                                               frameNum=frameNum)
            in_front_A = point_A_3d_4x1[2, 0] &gt; 0

            if in_front_A:
                polygon = polygon_A
            else:
                # Check if B
                point_B_3x1 = np.array([[point_B[0], point_B[1], 1]]).transpose()
                point_B_3d_4x1, valid = self.reproject_points2d_3xN(points2d_3xN=point_B_3x1, plane=(0, 0, 1, 0),
                                                                    cs_cam=camera_name, cs_dst=cs, frameNum=frameNum,
                                                                    apply_undistorsion=False)
                # Transform back to camera coordinate system
                point_B_3d_4x1 = self.transform_points3d_4xN(points3d_4xN=point_B_3d_4x1, cs_src=cs, cs_dst=camera_name,
                                                               frameNum=frameNum)
                in_front_B = point_B_3d_4x1[2, 0] &gt; 0

                if in_front_B:
                    polygon = polygon_B
                else:
                    # This should not happen... something&#39;s wrong
                    pass

        N = len(polygon)
        points2d_3xN = np.ones((3, N), dtype=np.int32)
        count = 0
        for point in polygon:
            points2d_3xN[0, count] = utils.round(point[0])
            points2d_3xN[1, count] = utils.round(point[1])
            count += 1

        return points2d_3xN

    def compute_horizon_line(self, camera_name, cs, frameNum=None):
        &#34;&#34;&#34;
        This function computes the horizon line (as the projection of the infinite Z=0) for a camera at a certain
        frameNum, in image coordinates.
        It works by creating 2 virtual infinite points in the Z=0, and projecting them into the image and clipping
        it adequately.
        Works using undistorted coordinates (otherwise, the horizon line is not a line but a curve).
        :param camera_name: camera name
        :param frameNum: frame number
        :return: line in general form (a, b, c), and array of points, all in undistorted domain
        &#34;&#34;&#34;
        if frameNum is None:
            f = -1
        else:
            f = frameNum

        # Perhaps already computed
        # TODO check if we really need to store this computation
        if camera_name in self.cameras:
            if f in self.cameras[camera_name]:
                if &#39;hline&#39; in self.cameras[camera_name][f]:
                    return self.cameras[camera_name][f][&#39;hline&#39;]

        # Compute
        cam = self.get_camera(camera_name=camera_name, frameNum=frameNum)
        width = cam.width
        height = cam.height

        # Select points in the infinite that belong to the Z=0 plane
        # Let&#39;s propose several infinite points in all 360º directions
        steps = 60
        step = 2*np.pi / steps
        points3d_inf = np.zeros((4, steps))
        for s in range(0, steps):
            angle = step*s
            x = np.cos(angle)
            y = np.sin(angle)
            points3d_inf[0, s] = x
            points3d_inf[1, s] = y

        # Convert from cs to camera_cs
        points3d_inf = self.transform_points3d_4xN(points3d_4xN=points3d_inf,
                                                   cs_src=cs, cs_dst=camera_name,
                                                   frameNum=frameNum)

        # Project in the camera (USING UNDISTORTED FRAME)
        points2d_inf, valid = cam.project_points3d(points3d_4xN=points3d_inf, apply_distortion=False)
        points2d_inf = points2d_inf[:, valid]
        if points2d_inf.shape[1] &lt; 2:
            return np.array([[]]), []

        ## From here on we have at least 2 valid infinite points projected in the image
        #points2d_inf = cam.undistort_points2d(points2d_dist_3xN=points2d_inf)

        # Let&#39;s choose two points (first and last) to define the line (ideally all of them should lie in the same line)
        n = points2d_inf.shape[1]
        # TODO: test all lie in the same line

        line = np.cross(points2d_inf[:, 0], points2d_inf[:, -1])
        line = line / np.linalg.norm(line)

        a = line[0]
        b = line[1]
        c = line[2]

        # ax + by + c = 0
        num_points_touch = 0
        points_horz = []
        if abs(a) &lt; 1e-8:
            # There is no intersection with X
            point_int_x0 = (0, -c / b)
            point_int_xW = (width, -c / b)
            if 0 &lt;= -c / b &lt; height:
                num_points_touch = 2
                points_horz.append(point_int_x0)
                points_horz.append(point_int_xW)

        elif abs(b) &lt; 1e-8:
            # There is no intersection with Y
            point_int_y0 = (-c / a, 0)
            point_int_yH = (-c / a, height)
            if 0 &lt;= -c / a &lt; width:
                num_points_touch = 2
                points_horz.append(point_int_y0)
                points_horz.append(point_int_yH)
        else:
            P1 = (0, -c / b)
            if 0 &lt;= P1[1] &lt; height:
                points_horz.append(P1)
            P2 = (width, -(c + a * width) / b)
            if 0 &lt;= P2[1] &lt; height:
                points_horz.append(P2)
            P3 = (-c / a, 0)
            if 0 &lt;= P3[0] &lt; width:
                points_horz.append(P3)
            P4 = (-(c + b * height) / a, height)
            if 0 &lt;= P4[0] &lt; width:
                points_horz.append(P4)

            assert (len(points_horz) == 2 or len(
                points_horz) == 0)  # a line can only intersect a rectangle in 2 points! (or none)

        # Store for next time
        self.cameras.setdefault(camera_name, {})
        self.cameras[camera_name].setdefault(frameNum, {})
        self.cameras[camera_name][frameNum][&#39;hline&#39;] = line, points_horz

        return line, points_horz

    def get_camera(self, camera_name, frameNum=None, compute_remaps=False):
        &#34;&#34;&#34;
        This function explores the VCD content searching for the camera parameters of camera &#34;camera_name&#34;, specific
        for frameNum if specified (or static information if None).

        The function consults and updates a store of information self.cameras, to speed up some computations (so they
        are carried out only once).

        Returns an object of type Camera, which can be used to project points, undistort images, etc.
        :param camera_name: name of the camera
        :param frameNum: frame number (if None, static camera info is requested)
        :return: Camera object
        &#34;&#34;&#34;
        # Check if already computed
        if frameNum is None:
            f = -1
        else:
            f = frameNum

        if camera_name in self.cameras:
            if f in self.cameras[camera_name]:
                return self.cameras[camera_name][f][&#39;cam&#39;]

        # Create camera m
        camera = None
        if &#39;streams&#39; in self.vcd.data[&#39;vcd&#39;]:
            if camera_name in self.vcd.data[&#39;vcd&#39;][&#39;streams&#39;]:
                uri = self.vcd.data[&#39;vcd&#39;][&#39;streams&#39;][camera_name][&#39;uri&#39;]
                description = self.vcd.data[&#39;vcd&#39;][&#39;streams&#39;][camera_name][&#39;description&#39;]
                if &#39;stream_properties&#39; in self.vcd.data[&#39;vcd&#39;][&#39;streams&#39;][camera_name]:
                    sp = self.vcd.data[&#39;vcd&#39;][&#39;streams&#39;][camera_name][&#39;stream_properties&#39;]
                    if &#39;intrinsics_pinhole&#39; in sp:
                        camera = CameraPinhole(sp[&#39;intrinsics_pinhole&#39;], camera_name, description, uri, compute_remaps)
                    elif &#39;intrinsics_fisheye&#39; in sp:
                        camera = CameraFisheye(sp[&#39;intrinsics_fisheye&#39;], camera_name, description, uri, compute_remaps)
        else:
            return None

        if frameNum is not None:
            vcd_frame = self.vcd.get_frame(frameNum)

            if &#39;frame_properties&#39; in vcd_frame:
                if &#39;streams&#39; in vcd_frame[&#39;frame_properties&#39;]:
                    if camera_name in vcd_frame[&#39;frame_properties&#39;][&#39;streams&#39;]:
                        if &#39;stream_properties&#39; in vcd_frame[&#39;frame_properties&#39;][&#39;streams&#39;][camera_name]:
                            sp = vcd_frame[&#39;frame_properties&#39;][&#39;streams&#39;][camera_name][
                                &#39;stream_properties&#39;]
                        if &#39;intrinsics_pinhole&#39; in sp:
                            camera = CameraPinhole(sp[&#39;intrinsics_pinhole&#39;], camera_name, description, uri, compute_remaps)
                        elif &#39;intrinsics_fisheye&#39; in sp:
                            camera = CameraFisheye(sp[&#39;intrinsics_fisheye&#39;], camera_name, description, uri, compute_remaps)

        # Update store
        self.cameras.setdefault(camera_name, {})
        self.cameras[camera_name].setdefault(f, {})
        self.cameras[camera_name][f][&#39;cam&#39;] = camera

        return camera

    def __get_transform_chain(self, cs_src, cs_dst):
        # Create graph with the poses defined for each coordinate_system
        # These are poses valid &#34;statically&#34;
        lista = []
        for cs_name, cs_body in self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;].items():
            for child in cs_body[&#39;children&#39;]:
                lista.append((cs_name, child, 1))
                lista.append((child, cs_name, 1))

        graph = Graph(lista)
        result = graph.dijkstra(cs_src, cs_dst)
        return result

    def get_transform(self, cs_src, cs_dst, frameNum=None):
        &#34;&#34;&#34;
        This function finds a 4x4 transform from the specified source coordinate system into the destination coordinate
        system, in a way points in the cs_src domain can be transformed to the cs_dst.
        The function works finding the chain of transforms needed to go from src to dst by exploring the parent-child
        dependencies declated in VCD.

        If the frameNum is specified, the function searches if any specific transform step at frameNum. If not found,
        static transforms are returned.
        :param cs_src: source coordinate frame (e.g. &#34;CAM_LEFT&#34;, or &#34;WORLD&#34;)
        :param cs_dst: destination coordinate frame (e.g. &#34;VELO&#34;, or &#34;CAM_LEFT&#34;)
        :param frameNum: frame number where to look for specific transform steps
        :return: the 4x4 transform matrix, and a boolean that specifies if the transform is static or not
        &#34;&#34;&#34;
        assert (self.vcd.has_coordinate_system(cs_src))
        assert (self.vcd.has_coordinate_system(cs_dst))

        static = True
        if cs_src == cs_dst:
            return np.eye(4), static

        # Get chain of transforms
        chain = self.__get_transform_chain(cs_src, cs_dst)

        # Let&#39;s build the transform using atomic transforms (which exist in VCD)
        t_4x4 = np.identity(4, dtype=float)
        for counter, value in enumerate(chain):
            # e.g. a) result = {(&#34;cam_left&#34;, &#34;velo_top&#34;), (&#34;velo_top&#34;, &#34;vehicle-iso8855&#34;)}
            # e.g. b) result = {(&#34;vehicle-iso8855&#34;, &#34;velo_top&#34;), (&#34;velo_top&#34;, &#34;cam_left&#34;)}
            if counter == len(chain) - 1:
                break
            cs_1 = chain[counter]
            cs_2 = chain[counter + 1]

            t_name = cs_1 + &#34;_to_&#34; + cs_2
            t_name_inv = cs_2 + &#34;_to_&#34; + cs_1

            # NOTE: this entire function works under the consensus that pose_src_wrt_dst = transform_src_to_dst, using
            # alias rotation of coordinate systems and linear 4x4
            if frameNum is None:
                # No frame info, let&#39;s read from coordinate_system poses
                # Check if this edge is from child to parent or viceversa
                if cs_2 == self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_1][&#39;parent&#39;]:
                    t_4x4 = (
                        np.array([self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_1][&#39;pose_wrt_parent&#39;]]).reshape(4, 4)).dot(
                        t_4x4)
                elif cs_1 == self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_2][&#39;parent&#39;]:
                    temp = np.array([self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_2][&#39;pose_wrt_parent&#39;]])
                    t_4x4 = utils.inv(temp.reshape(4, 4)).dot(t_4x4)
            else:
                # So the user has asked for a specific frame, let&#39;s look for this frame if a transform exist
                transform_at_this_frame = False
                if frameNum in self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;]:
                    if &#39;frame_properties&#39; in self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum]:
                        if &#39;transforms&#39; in self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum][&#39;frame_properties&#39;]:
                            if t_name in self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum][&#39;frame_properties&#39;][&#39;transforms&#39;]:
                                transform = self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum][&#39;frame_properties&#39;][&#39;transforms&#39;][t_name]
                                t_4x4 = (np.array([transform[&#39;transform_src_to_dst_4x4&#39;]]).reshape(4, 4)).dot(t_4x4)
                                static = False  # with one non-static step the entire chain can be considered not static
                                transform_at_this_frame = True
                            elif t_name_inv in self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum][&#39;frame_properties&#39;][&#39;transforms&#39;]:
                                transform = self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum][&#39;frame_properties&#39;][&#39;transforms&#39;][
                                    t_name_inv]
                                temp = np.array([transform[&#39;transform_src_to_dst_4x4&#39;]])
                                t_4x4 = utils.inv(temp.reshape(4, 4)).dot(t_4x4)
                                static = False
                                transform_at_this_frame = True
                if not transform_at_this_frame:
                    # Reached this point means no transforms were defined at the requested frameNum
                    # Check if this edge is from child to parent or viceversa
                    if cs_2 == self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_1][&#39;parent&#39;]:
                        t_4x4 = (np.array([self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_1][&#39;pose_wrt_parent&#39;]]).reshape(4,
                                                                                                                    4)).dot(
                            t_4x4)
                    elif cs_1 == self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_2][&#39;parent&#39;]:
                        temp = np.array([self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_2][&#39;pose_wrt_parent&#39;]])
                        t_4x4 = utils.inv(temp.reshape(4, 4)).dot(t_4x4)

        return t_4x4, static

    def transform_points3d_4xN(self, points3d_4xN, cs_src, cs_dst, frameNum=None):
        transform_src_dst, static = self.get_transform(cs_src, cs_dst, frameNum)
        if transform_src_dst is not None:
            points3d_dst_4xN = utils.transform_points3d_4xN(points3d_4xN, transform_src_dst)
            return points3d_dst_4xN
        else:
            return None

    def transform_cuboid(self, cuboid_vals, cs_src, cs_dst, frameNum=None):
        transform_src_dst, static = self.get_transform(cs_src, cs_dst, frameNum)

        if transform_src_dst is not None:
            cuboid_vals_transformed = utils.transform_cuboid(cuboid_vals, transform_src_dst)
            return cuboid_vals_transformed
        else:
            return cuboid_vals

    def transform_plane(self, plane_abcd, cs_src, cs_dst, frameNum=None):
        transform_src_dst, static = self.get_transform(cs_src, cs_dst, frameNum)
        if transform_src_dst is not None:
            plane_abcd_transformed = utils.transform_plane(plane_abcd, transform_src_dst)
            return plane_abcd_transformed
        else:
            return plane_abcd

    def project_points3d_4xN(self, points3d_4xN, cs_src, cs_cam, frameNum=None, apply_distortion=True, remove_outside=False):
        &#34;&#34;&#34;
        This function projects 3D points into a given camera, specifying the origin coordinate system of the points,
        and a certain frame number. Optionally, distortion can be applied or not (e.g. sometimes is useful to project
        into the undistorted domain).
        :param points3d_4xN: array of 4xN 3D points in cs_src coordinate system
        :param cs_src: name of coordinate system of the points
        :param cs_cam: name of the camera
        :param frameNum: frame number (if None, static camera info is seeked)
        :param apply_distortion: default to True, if False, projection is carried out into undistorted domain
        :param remove_outside: flag to invalidate points outside the limits of the image domain
        :return: array of 3xN 2D points in image coordinates (distorted or undistorted according to apply_distortion),
        and array of boolean declaring points valid or not
        &#34;&#34;&#34;
        points3d_camera_cs_4xN = self.transform_points3d_4xN(points3d_4xN=points3d_4xN,
                                                             cs_src=cs_src, cs_dst=cs_cam,
                                                             frameNum=frameNum)
        if points3d_camera_cs_4xN is not None:
            cam = self.get_camera(camera_name=cs_cam, frameNum=frameNum)
            points2d_3xN, idx_valid = cam.project_points3d(points3d_4xN=points3d_camera_cs_4xN,
                                                           apply_distortion=apply_distortion,
                                                           remove_outside=remove_outside)
            return points2d_3xN, idx_valid
        return np.array([[]]), []

    def reproject_points2d_3xN(self, points2d_3xN, plane, cs_cam, cs_dst, frameNum=None, apply_undistorsion=True):
        # This function calls a camera (cs_cam) to reproject points2d in the image plane into
        # a plane defined in the cs_dst.
        # The obtained 3D points are expressed in cs_dst.
        # idx_valid identifies which points are valid 3D points (the reprojection might point to infinity)
        cam = self.get_camera(cs_cam, frameNum)
        plane_cam = self.transform_plane(plane, cs_dst, cs_cam, frameNum) # first convert plane into cam cs
        N = points2d_3xN.shape[1]
        points3d_3xN_cs_cam, idx_valid = cam.reproject_points2d(points2d_3xN, plane_cam, apply_undistorsion)
        if points3d_3xN_cs_cam.shape[1] &gt; 0:
            points3d_3xN_cs_cam_filt = points3d_3xN_cs_cam[:, idx_valid]
            points3d_4xN_cs_dst_filt = self.transform_points3d_4xN(points3d_3xN_cs_cam_filt, cs_cam, cs_dst, frameNum)
            points3d_4xN_cs_dst = np.full([4, N], np.nan)
            points3d_4xN_cs_dst[:, idx_valid] = points3d_4xN_cs_dst_filt
            return points3d_4xN_cs_dst, idx_valid
        return np.array([[]]), []</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="vcd.scl.Scene.camera_roi_z0"><code class="name flex">
<span>def <span class="ident">camera_roi_z0</span></span>(<span>self, camera_name, cs, frameNum)</span>
</code></dt>
<dd>
<div class="desc"><p>This function computes the region of the image which maps into the reference (cs) Z=0 plane
by checking whether the re-projected point lies in front or behind the camera
:param cam_name: camera name
:param frameNum: frame num
:return: polygon 2D</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def camera_roi_z0(self, camera_name, cs, frameNum):
    &#34;&#34;&#34;
    This function computes the region of the image which maps into the reference (cs) Z=0 plane
    by checking whether the re-projected point lies in front or behind the camera
    :param cam_name: camera name
    :param frameNum: frame num
    :return: polygon 2D
    &#34;&#34;&#34;
    # Working on undistorted coordinates
    hline, points = self.compute_horizon_line(camera_name=camera_name, cs=cs, frameNum=frameNum)
    cam = self.get_camera(camera_name=camera_name, frameNum=frameNum)
    width = cam.img_size_undist[0]
    height = cam.img_size_undist[1]

    # Create 2 contours going through the limits of the image and using points
    # Then check which of them contains points which are projected in Z&gt;0 in camera coordinate system
    polygon = []
    if len(points) == 0:
        # So, the line at the infinite is NOT inside the limits of the image
        # Let&#39;s then check if any point inside the image produces a Z&gt;0 (if not, this camera is pointing to the sky)
        point2d_dist_3x1 = np.array([[width / 2, height / 2, 1]]).transpose()

        # Reproject into self.coordinate_system Z=0 plane
        point3d_4x1, valid = self.reproject_points2d_3xN(points2d_3xN=point2d_dist_3x1, plane=(0, 0, 1, 0),
                                                         cs_cam=camera_name, cs_dst=cs, frameNum=frameNum,
                                                         apply_undistorsion=False)
        # Transform back to camera coordinate system
        point3d_4x1 = self.transform_points3d_4xN(points3d_4xN=point3d_4x1, cs_src=cs, cs_dst=camera_name,
                                                  frameNum=frameNum)
        in_front = point3d_4x1[2, 0] &gt; 0
        if in_front:
            polygon.append((0, 0))
            polygon.append((width - 1, 0))
            polygon.append((width - 1, height - 1))
            polygon.append((0, height - 1))

            return polygon
    else:
        # Ok, so the horizon line is INSIDE the limits of the undistorted domain
        # There are 6 possible configurations
        points_code = []
        U = None
        L = None
        R = None
        B = None
        for idx, point in enumerate(points):
            if point[1] == 0:  # So points[0] is U
                points_code.append(&#39;U&#39;)
                U = point
            elif point[0] == width:
                points_code.append(&#39;R&#39;)
                R = point
            elif point[1] == height:
                points_code.append(&#39;B&#39;)
                B = point
            else:
                points_code.append(&#39;L&#39;)
                L = point
        UL = (0, 0)
        UR = (width - 1, 0)
        BR = (width - 1, height - 1)
        BL = (0, height - 1)

        polygon_A = []
        polygon_B = []
        if &#39;U&#39; in points_code and &#39;L&#39; in points_code:
            # Case 0: LU
            polygon_A.append(UL)
            polygon_A.append(U)
            polygon_A.append(L)
            polygon_A.append(U)
            polygon_B.append(UR)
            polygon_B.append(BR)
            polygon_B.append(BL)
            polygon_B.append(L)
        elif &#39;U&#39; in points_code and &#39;B&#39; in points_code:
            # Case 1: BU
            polygon_A.append(UL)
            polygon_A.append(U)
            polygon_A.append(B)
            polygon_A.append(BL)
            polygon_B.append(U)
            polygon_B.append(UR)
            polygon_B.append(BR)
            polygon_B.append(B)
        elif &#39;U&#39; in points_code and &#39;R&#39; in points_code:
            # Case 2: RU
            polygon_A.append(U)
            polygon_A.append(UR)
            polygon_A.append(R)
            polygon_B.append(UL)
            polygon_B.append(U)
            polygon_B.append(R)
            polygon_B.append(BR)
            polygon_B.append(BL)
        elif &#39;L&#39; in points_code and &#39;B&#39; in points_code:
            # Case 3: LB
            polygon_A.append(L)
            polygon_A.append(B)
            polygon_A.append(BL)
            polygon_B.append(UL)
            polygon_B.append(UR)
            polygon_B.append(BR)
            polygon_B.append(B)
            polygon_B.append(L)
        elif &#39;L&#39; in points_code and &#39;R&#39; in points_code:
            # Case 4: LR
            polygon_A.append(UL)
            polygon_A.append(UR)
            polygon_A.append(R)
            polygon_A.append(L)
            polygon_B.append(L)
            polygon_B.append(R)
            polygon_B.append(BR)
            polygon_B.append(BL)
        else:
            # Case 5: BR
            polygon_A.append(B)
            polygon_A.append(R)
            polygon_A.append(BR)
            polygon_B.append(UL)
            polygon_B.append(UR)
            polygon_B.append(R)
            polygon_B.append(B)
            polygon_B.append(BR)

        # Now test whether polygon or polygon_other contain points which project to z&gt;0 camera
        point_A = (sum(x for x, y in polygon_A), sum(y for x, y in polygon_A))
        point_A = (point_A[0]/len(polygon_A), point_A[1]/len(polygon_A))

        point_B = (sum(x for x, y in polygon_B), sum(y for x, y in polygon_B))
        point_B = (point_B[0] / len(polygon_B), point_B[1] / len(polygon_B))

        # Reproject into self.coordinate_system Z=0 plane
        point_A_3x1 = np.array([[point_A[0], point_A[1], 1]]).transpose()
        point_A_3d_4x1, valid = self.reproject_points2d_3xN(points2d_3xN=point_A_3x1, plane=(0, 0, 1, 0),
                                                            cs_cam=camera_name, cs_dst=cs, frameNum=frameNum,
                                                            apply_undistorsion=False)
        # Transform back to camera coordinate system
        point_A_3d_4x1 = self.transform_points3d_4xN(points3d_4xN=point_A_3d_4x1, cs_src=cs, cs_dst=camera_name,
                                                           frameNum=frameNum)
        in_front_A = point_A_3d_4x1[2, 0] &gt; 0

        if in_front_A:
            polygon = polygon_A
        else:
            # Check if B
            point_B_3x1 = np.array([[point_B[0], point_B[1], 1]]).transpose()
            point_B_3d_4x1, valid = self.reproject_points2d_3xN(points2d_3xN=point_B_3x1, plane=(0, 0, 1, 0),
                                                                cs_cam=camera_name, cs_dst=cs, frameNum=frameNum,
                                                                apply_undistorsion=False)
            # Transform back to camera coordinate system
            point_B_3d_4x1 = self.transform_points3d_4xN(points3d_4xN=point_B_3d_4x1, cs_src=cs, cs_dst=camera_name,
                                                           frameNum=frameNum)
            in_front_B = point_B_3d_4x1[2, 0] &gt; 0

            if in_front_B:
                polygon = polygon_B
            else:
                # This should not happen... something&#39;s wrong
                pass

    N = len(polygon)
    points2d_3xN = np.ones((3, N), dtype=np.int32)
    count = 0
    for point in polygon:
        points2d_3xN[0, count] = utils.round(point[0])
        points2d_3xN[1, count] = utils.round(point[1])
        count += 1

    return points2d_3xN</code></pre>
</details>
</dd>
<dt id="vcd.scl.Scene.compute_horizon_line"><code class="name flex">
<span>def <span class="ident">compute_horizon_line</span></span>(<span>self, camera_name, cs, frameNum=None)</span>
</code></dt>
<dd>
<div class="desc"><p>This function computes the horizon line (as the projection of the infinite Z=0) for a camera at a certain
frameNum, in image coordinates.
It works by creating 2 virtual infinite points in the Z=0, and projecting them into the image and clipping
it adequately.
Works using undistorted coordinates (otherwise, the horizon line is not a line but a curve).
:param camera_name: camera name
:param frameNum: frame number
:return: line in general form (a, b, c), and array of points, all in undistorted domain</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_horizon_line(self, camera_name, cs, frameNum=None):
    &#34;&#34;&#34;
    This function computes the horizon line (as the projection of the infinite Z=0) for a camera at a certain
    frameNum, in image coordinates.
    It works by creating 2 virtual infinite points in the Z=0, and projecting them into the image and clipping
    it adequately.
    Works using undistorted coordinates (otherwise, the horizon line is not a line but a curve).
    :param camera_name: camera name
    :param frameNum: frame number
    :return: line in general form (a, b, c), and array of points, all in undistorted domain
    &#34;&#34;&#34;
    if frameNum is None:
        f = -1
    else:
        f = frameNum

    # Perhaps already computed
    # TODO check if we really need to store this computation
    if camera_name in self.cameras:
        if f in self.cameras[camera_name]:
            if &#39;hline&#39; in self.cameras[camera_name][f]:
                return self.cameras[camera_name][f][&#39;hline&#39;]

    # Compute
    cam = self.get_camera(camera_name=camera_name, frameNum=frameNum)
    width = cam.width
    height = cam.height

    # Select points in the infinite that belong to the Z=0 plane
    # Let&#39;s propose several infinite points in all 360º directions
    steps = 60
    step = 2*np.pi / steps
    points3d_inf = np.zeros((4, steps))
    for s in range(0, steps):
        angle = step*s
        x = np.cos(angle)
        y = np.sin(angle)
        points3d_inf[0, s] = x
        points3d_inf[1, s] = y

    # Convert from cs to camera_cs
    points3d_inf = self.transform_points3d_4xN(points3d_4xN=points3d_inf,
                                               cs_src=cs, cs_dst=camera_name,
                                               frameNum=frameNum)

    # Project in the camera (USING UNDISTORTED FRAME)
    points2d_inf, valid = cam.project_points3d(points3d_4xN=points3d_inf, apply_distortion=False)
    points2d_inf = points2d_inf[:, valid]
    if points2d_inf.shape[1] &lt; 2:
        return np.array([[]]), []

    ## From here on we have at least 2 valid infinite points projected in the image
    #points2d_inf = cam.undistort_points2d(points2d_dist_3xN=points2d_inf)

    # Let&#39;s choose two points (first and last) to define the line (ideally all of them should lie in the same line)
    n = points2d_inf.shape[1]
    # TODO: test all lie in the same line

    line = np.cross(points2d_inf[:, 0], points2d_inf[:, -1])
    line = line / np.linalg.norm(line)

    a = line[0]
    b = line[1]
    c = line[2]

    # ax + by + c = 0
    num_points_touch = 0
    points_horz = []
    if abs(a) &lt; 1e-8:
        # There is no intersection with X
        point_int_x0 = (0, -c / b)
        point_int_xW = (width, -c / b)
        if 0 &lt;= -c / b &lt; height:
            num_points_touch = 2
            points_horz.append(point_int_x0)
            points_horz.append(point_int_xW)

    elif abs(b) &lt; 1e-8:
        # There is no intersection with Y
        point_int_y0 = (-c / a, 0)
        point_int_yH = (-c / a, height)
        if 0 &lt;= -c / a &lt; width:
            num_points_touch = 2
            points_horz.append(point_int_y0)
            points_horz.append(point_int_yH)
    else:
        P1 = (0, -c / b)
        if 0 &lt;= P1[1] &lt; height:
            points_horz.append(P1)
        P2 = (width, -(c + a * width) / b)
        if 0 &lt;= P2[1] &lt; height:
            points_horz.append(P2)
        P3 = (-c / a, 0)
        if 0 &lt;= P3[0] &lt; width:
            points_horz.append(P3)
        P4 = (-(c + b * height) / a, height)
        if 0 &lt;= P4[0] &lt; width:
            points_horz.append(P4)

        assert (len(points_horz) == 2 or len(
            points_horz) == 0)  # a line can only intersect a rectangle in 2 points! (or none)

    # Store for next time
    self.cameras.setdefault(camera_name, {})
    self.cameras[camera_name].setdefault(frameNum, {})
    self.cameras[camera_name][frameNum][&#39;hline&#39;] = line, points_horz

    return line, points_horz</code></pre>
</details>
</dd>
<dt id="vcd.scl.Scene.get_camera"><code class="name flex">
<span>def <span class="ident">get_camera</span></span>(<span>self, camera_name, frameNum=None, compute_remaps=False)</span>
</code></dt>
<dd>
<div class="desc"><p>This function explores the VCD content searching for the camera parameters of camera "camera_name", specific
for frameNum if specified (or static information if None).</p>
<p>The function consults and updates a store of information self.cameras, to speed up some computations (so they
are carried out only once).</p>
<p>Returns an object of type Camera, which can be used to project points, undistort images, etc.
:param camera_name: name of the camera
:param frameNum: frame number (if None, static camera info is requested)
:return: Camera object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_camera(self, camera_name, frameNum=None, compute_remaps=False):
    &#34;&#34;&#34;
    This function explores the VCD content searching for the camera parameters of camera &#34;camera_name&#34;, specific
    for frameNum if specified (or static information if None).

    The function consults and updates a store of information self.cameras, to speed up some computations (so they
    are carried out only once).

    Returns an object of type Camera, which can be used to project points, undistort images, etc.
    :param camera_name: name of the camera
    :param frameNum: frame number (if None, static camera info is requested)
    :return: Camera object
    &#34;&#34;&#34;
    # Check if already computed
    if frameNum is None:
        f = -1
    else:
        f = frameNum

    if camera_name in self.cameras:
        if f in self.cameras[camera_name]:
            return self.cameras[camera_name][f][&#39;cam&#39;]

    # Create camera m
    camera = None
    if &#39;streams&#39; in self.vcd.data[&#39;vcd&#39;]:
        if camera_name in self.vcd.data[&#39;vcd&#39;][&#39;streams&#39;]:
            uri = self.vcd.data[&#39;vcd&#39;][&#39;streams&#39;][camera_name][&#39;uri&#39;]
            description = self.vcd.data[&#39;vcd&#39;][&#39;streams&#39;][camera_name][&#39;description&#39;]
            if &#39;stream_properties&#39; in self.vcd.data[&#39;vcd&#39;][&#39;streams&#39;][camera_name]:
                sp = self.vcd.data[&#39;vcd&#39;][&#39;streams&#39;][camera_name][&#39;stream_properties&#39;]
                if &#39;intrinsics_pinhole&#39; in sp:
                    camera = CameraPinhole(sp[&#39;intrinsics_pinhole&#39;], camera_name, description, uri, compute_remaps)
                elif &#39;intrinsics_fisheye&#39; in sp:
                    camera = CameraFisheye(sp[&#39;intrinsics_fisheye&#39;], camera_name, description, uri, compute_remaps)
    else:
        return None

    if frameNum is not None:
        vcd_frame = self.vcd.get_frame(frameNum)

        if &#39;frame_properties&#39; in vcd_frame:
            if &#39;streams&#39; in vcd_frame[&#39;frame_properties&#39;]:
                if camera_name in vcd_frame[&#39;frame_properties&#39;][&#39;streams&#39;]:
                    if &#39;stream_properties&#39; in vcd_frame[&#39;frame_properties&#39;][&#39;streams&#39;][camera_name]:
                        sp = vcd_frame[&#39;frame_properties&#39;][&#39;streams&#39;][camera_name][
                            &#39;stream_properties&#39;]
                    if &#39;intrinsics_pinhole&#39; in sp:
                        camera = CameraPinhole(sp[&#39;intrinsics_pinhole&#39;], camera_name, description, uri, compute_remaps)
                    elif &#39;intrinsics_fisheye&#39; in sp:
                        camera = CameraFisheye(sp[&#39;intrinsics_fisheye&#39;], camera_name, description, uri, compute_remaps)

    # Update store
    self.cameras.setdefault(camera_name, {})
    self.cameras[camera_name].setdefault(f, {})
    self.cameras[camera_name][f][&#39;cam&#39;] = camera

    return camera</code></pre>
</details>
</dd>
<dt id="vcd.scl.Scene.get_transform"><code class="name flex">
<span>def <span class="ident">get_transform</span></span>(<span>self, cs_src, cs_dst, frameNum=None)</span>
</code></dt>
<dd>
<div class="desc"><p>This function finds a 4x4 transform from the specified source coordinate system into the destination coordinate
system, in a way points in the cs_src domain can be transformed to the cs_dst.
The function works finding the chain of transforms needed to go from src to dst by exploring the parent-child
dependencies declated in VCD.</p>
<p>If the frameNum is specified, the function searches if any specific transform step at frameNum. If not found,
static transforms are returned.
:param cs_src: source coordinate frame (e.g. "CAM_LEFT", or "WORLD")
:param cs_dst: destination coordinate frame (e.g. "VELO", or "CAM_LEFT")
:param frameNum: frame number where to look for specific transform steps
:return: the 4x4 transform matrix, and a boolean that specifies if the transform is static or not</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_transform(self, cs_src, cs_dst, frameNum=None):
    &#34;&#34;&#34;
    This function finds a 4x4 transform from the specified source coordinate system into the destination coordinate
    system, in a way points in the cs_src domain can be transformed to the cs_dst.
    The function works finding the chain of transforms needed to go from src to dst by exploring the parent-child
    dependencies declated in VCD.

    If the frameNum is specified, the function searches if any specific transform step at frameNum. If not found,
    static transforms are returned.
    :param cs_src: source coordinate frame (e.g. &#34;CAM_LEFT&#34;, or &#34;WORLD&#34;)
    :param cs_dst: destination coordinate frame (e.g. &#34;VELO&#34;, or &#34;CAM_LEFT&#34;)
    :param frameNum: frame number where to look for specific transform steps
    :return: the 4x4 transform matrix, and a boolean that specifies if the transform is static or not
    &#34;&#34;&#34;
    assert (self.vcd.has_coordinate_system(cs_src))
    assert (self.vcd.has_coordinate_system(cs_dst))

    static = True
    if cs_src == cs_dst:
        return np.eye(4), static

    # Get chain of transforms
    chain = self.__get_transform_chain(cs_src, cs_dst)

    # Let&#39;s build the transform using atomic transforms (which exist in VCD)
    t_4x4 = np.identity(4, dtype=float)
    for counter, value in enumerate(chain):
        # e.g. a) result = {(&#34;cam_left&#34;, &#34;velo_top&#34;), (&#34;velo_top&#34;, &#34;vehicle-iso8855&#34;)}
        # e.g. b) result = {(&#34;vehicle-iso8855&#34;, &#34;velo_top&#34;), (&#34;velo_top&#34;, &#34;cam_left&#34;)}
        if counter == len(chain) - 1:
            break
        cs_1 = chain[counter]
        cs_2 = chain[counter + 1]

        t_name = cs_1 + &#34;_to_&#34; + cs_2
        t_name_inv = cs_2 + &#34;_to_&#34; + cs_1

        # NOTE: this entire function works under the consensus that pose_src_wrt_dst = transform_src_to_dst, using
        # alias rotation of coordinate systems and linear 4x4
        if frameNum is None:
            # No frame info, let&#39;s read from coordinate_system poses
            # Check if this edge is from child to parent or viceversa
            if cs_2 == self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_1][&#39;parent&#39;]:
                t_4x4 = (
                    np.array([self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_1][&#39;pose_wrt_parent&#39;]]).reshape(4, 4)).dot(
                    t_4x4)
            elif cs_1 == self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_2][&#39;parent&#39;]:
                temp = np.array([self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_2][&#39;pose_wrt_parent&#39;]])
                t_4x4 = utils.inv(temp.reshape(4, 4)).dot(t_4x4)
        else:
            # So the user has asked for a specific frame, let&#39;s look for this frame if a transform exist
            transform_at_this_frame = False
            if frameNum in self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;]:
                if &#39;frame_properties&#39; in self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum]:
                    if &#39;transforms&#39; in self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum][&#39;frame_properties&#39;]:
                        if t_name in self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum][&#39;frame_properties&#39;][&#39;transforms&#39;]:
                            transform = self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum][&#39;frame_properties&#39;][&#39;transforms&#39;][t_name]
                            t_4x4 = (np.array([transform[&#39;transform_src_to_dst_4x4&#39;]]).reshape(4, 4)).dot(t_4x4)
                            static = False  # with one non-static step the entire chain can be considered not static
                            transform_at_this_frame = True
                        elif t_name_inv in self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum][&#39;frame_properties&#39;][&#39;transforms&#39;]:
                            transform = self.vcd.data[&#39;vcd&#39;][&#39;frames&#39;][frameNum][&#39;frame_properties&#39;][&#39;transforms&#39;][
                                t_name_inv]
                            temp = np.array([transform[&#39;transform_src_to_dst_4x4&#39;]])
                            t_4x4 = utils.inv(temp.reshape(4, 4)).dot(t_4x4)
                            static = False
                            transform_at_this_frame = True
            if not transform_at_this_frame:
                # Reached this point means no transforms were defined at the requested frameNum
                # Check if this edge is from child to parent or viceversa
                if cs_2 == self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_1][&#39;parent&#39;]:
                    t_4x4 = (np.array([self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_1][&#39;pose_wrt_parent&#39;]]).reshape(4,
                                                                                                                4)).dot(
                        t_4x4)
                elif cs_1 == self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_2][&#39;parent&#39;]:
                    temp = np.array([self.vcd.data[&#39;vcd&#39;][&#39;coordinate_systems&#39;][cs_2][&#39;pose_wrt_parent&#39;]])
                    t_4x4 = utils.inv(temp.reshape(4, 4)).dot(t_4x4)

    return t_4x4, static</code></pre>
</details>
</dd>
<dt id="vcd.scl.Scene.project_points3d_4xN"><code class="name flex">
<span>def <span class="ident">project_points3d_4xN</span></span>(<span>self, points3d_4xN, cs_src, cs_cam, frameNum=None, apply_distortion=True, remove_outside=False)</span>
</code></dt>
<dd>
<div class="desc"><p>This function projects 3D points into a given camera, specifying the origin coordinate system of the points,
and a certain frame number. Optionally, distortion can be applied or not (e.g. sometimes is useful to project
into the undistorted domain).
:param points3d_4xN: array of 4xN 3D points in cs_src coordinate system
:param cs_src: name of coordinate system of the points
:param cs_cam: name of the camera
:param frameNum: frame number (if None, static camera info is seeked)
:param apply_distortion: default to True, if False, projection is carried out into undistorted domain
:param remove_outside: flag to invalidate points outside the limits of the image domain
:return: array of 3xN 2D points in image coordinates (distorted or undistorted according to apply_distortion),
and array of boolean declaring points valid or not</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def project_points3d_4xN(self, points3d_4xN, cs_src, cs_cam, frameNum=None, apply_distortion=True, remove_outside=False):
    &#34;&#34;&#34;
    This function projects 3D points into a given camera, specifying the origin coordinate system of the points,
    and a certain frame number. Optionally, distortion can be applied or not (e.g. sometimes is useful to project
    into the undistorted domain).
    :param points3d_4xN: array of 4xN 3D points in cs_src coordinate system
    :param cs_src: name of coordinate system of the points
    :param cs_cam: name of the camera
    :param frameNum: frame number (if None, static camera info is seeked)
    :param apply_distortion: default to True, if False, projection is carried out into undistorted domain
    :param remove_outside: flag to invalidate points outside the limits of the image domain
    :return: array of 3xN 2D points in image coordinates (distorted or undistorted according to apply_distortion),
    and array of boolean declaring points valid or not
    &#34;&#34;&#34;
    points3d_camera_cs_4xN = self.transform_points3d_4xN(points3d_4xN=points3d_4xN,
                                                         cs_src=cs_src, cs_dst=cs_cam,
                                                         frameNum=frameNum)
    if points3d_camera_cs_4xN is not None:
        cam = self.get_camera(camera_name=cs_cam, frameNum=frameNum)
        points2d_3xN, idx_valid = cam.project_points3d(points3d_4xN=points3d_camera_cs_4xN,
                                                       apply_distortion=apply_distortion,
                                                       remove_outside=remove_outside)
        return points2d_3xN, idx_valid
    return np.array([[]]), []</code></pre>
</details>
</dd>
<dt id="vcd.scl.Scene.reproject_points2d_3xN"><code class="name flex">
<span>def <span class="ident">reproject_points2d_3xN</span></span>(<span>self, points2d_3xN, plane, cs_cam, cs_dst, frameNum=None, apply_undistorsion=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reproject_points2d_3xN(self, points2d_3xN, plane, cs_cam, cs_dst, frameNum=None, apply_undistorsion=True):
    # This function calls a camera (cs_cam) to reproject points2d in the image plane into
    # a plane defined in the cs_dst.
    # The obtained 3D points are expressed in cs_dst.
    # idx_valid identifies which points are valid 3D points (the reprojection might point to infinity)
    cam = self.get_camera(cs_cam, frameNum)
    plane_cam = self.transform_plane(plane, cs_dst, cs_cam, frameNum) # first convert plane into cam cs
    N = points2d_3xN.shape[1]
    points3d_3xN_cs_cam, idx_valid = cam.reproject_points2d(points2d_3xN, plane_cam, apply_undistorsion)
    if points3d_3xN_cs_cam.shape[1] &gt; 0:
        points3d_3xN_cs_cam_filt = points3d_3xN_cs_cam[:, idx_valid]
        points3d_4xN_cs_dst_filt = self.transform_points3d_4xN(points3d_3xN_cs_cam_filt, cs_cam, cs_dst, frameNum)
        points3d_4xN_cs_dst = np.full([4, N], np.nan)
        points3d_4xN_cs_dst[:, idx_valid] = points3d_4xN_cs_dst_filt
        return points3d_4xN_cs_dst, idx_valid
    return np.array([[]]), []</code></pre>
</details>
</dd>
<dt id="vcd.scl.Scene.transform_cuboid"><code class="name flex">
<span>def <span class="ident">transform_cuboid</span></span>(<span>self, cuboid_vals, cs_src, cs_dst, frameNum=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform_cuboid(self, cuboid_vals, cs_src, cs_dst, frameNum=None):
    transform_src_dst, static = self.get_transform(cs_src, cs_dst, frameNum)

    if transform_src_dst is not None:
        cuboid_vals_transformed = utils.transform_cuboid(cuboid_vals, transform_src_dst)
        return cuboid_vals_transformed
    else:
        return cuboid_vals</code></pre>
</details>
</dd>
<dt id="vcd.scl.Scene.transform_plane"><code class="name flex">
<span>def <span class="ident">transform_plane</span></span>(<span>self, plane_abcd, cs_src, cs_dst, frameNum=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform_plane(self, plane_abcd, cs_src, cs_dst, frameNum=None):
    transform_src_dst, static = self.get_transform(cs_src, cs_dst, frameNum)
    if transform_src_dst is not None:
        plane_abcd_transformed = utils.transform_plane(plane_abcd, transform_src_dst)
        return plane_abcd_transformed
    else:
        return plane_abcd</code></pre>
</details>
</dd>
<dt id="vcd.scl.Scene.transform_points3d_4xN"><code class="name flex">
<span>def <span class="ident">transform_points3d_4xN</span></span>(<span>self, points3d_4xN, cs_src, cs_dst, frameNum=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform_points3d_4xN(self, points3d_4xN, cs_src, cs_dst, frameNum=None):
    transform_src_dst, static = self.get_transform(cs_src, cs_dst, frameNum)
    if transform_src_dst is not None:
        points3d_dst_4xN = utils.transform_points3d_4xN(points3d_4xN, transform_src_dst)
        return points3d_dst_4xN
    else:
        return None</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="vcd.scl.Sensor"><code class="flex name class">
<span>class <span class="ident">Sensor</span></span>
<span>(</span><span>name, description, uri, **properties)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Sensor:
    def __init__(self, name, description, uri, **properties):
        self.name = name
        self.description = description
        self.uri = uri
        self.type = type(self).__name__

        self.properties = properties  # additional properties

    def is_camera(self):
        if self.type == &#34;CameraPinhole&#34; or self.type == &#34;CameraFisheye&#34; or self.type == &#34;CameraEquirectangular&#34;:
            return True
        return False

    def is_lidar(self):
        if self.type == &#34;Lidar&#34;:
            return True
        return False</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="vcd.scl.Camera" href="#vcd.scl.Camera">Camera</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="vcd.scl.Sensor.is_camera"><code class="name flex">
<span>def <span class="ident">is_camera</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_camera(self):
    if self.type == &#34;CameraPinhole&#34; or self.type == &#34;CameraFisheye&#34; or self.type == &#34;CameraEquirectangular&#34;:
        return True
    return False</code></pre>
</details>
</dd>
<dt id="vcd.scl.Sensor.is_lidar"><code class="name flex">
<span>def <span class="ident">is_lidar</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_lidar(self):
    if self.type == &#34;Lidar&#34;:
        return True
    return False</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="vcd" href="index.html">vcd</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="vcd.scl.make_edge" href="#vcd.scl.make_edge">make_edge</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="vcd.scl.Camera" href="#vcd.scl.Camera">Camera</a></code></h4>
<ul class="">
<li><code><a title="vcd.scl.Camera.project_points3d" href="#vcd.scl.Camera.project_points3d">project_points3d</a></code></li>
<li><code><a title="vcd.scl.Camera.reproject_points2d" href="#vcd.scl.Camera.reproject_points2d">reproject_points2d</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="vcd.scl.CameraFisheye" href="#vcd.scl.CameraFisheye">CameraFisheye</a></code></h4>
<ul class="">
<li><code><a title="vcd.scl.CameraFisheye.distort_points2d" href="#vcd.scl.CameraFisheye.distort_points2d">distort_points2d</a></code></li>
<li><code><a title="vcd.scl.CameraFisheye.distort_rays3d" href="#vcd.scl.CameraFisheye.distort_rays3d">distort_rays3d</a></code></li>
<li><code><a title="vcd.scl.CameraFisheye.estimate_new_camera_matrix_for_undistort_rectify" href="#vcd.scl.CameraFisheye.estimate_new_camera_matrix_for_undistort_rectify">estimate_new_camera_matrix_for_undistort_rectify</a></code></li>
<li><code><a title="vcd.scl.CameraFisheye.init_undistort_rectify_map" href="#vcd.scl.CameraFisheye.init_undistort_rectify_map">init_undistort_rectify_map</a></code></li>
<li><code><a title="vcd.scl.CameraFisheye.is_distorted" href="#vcd.scl.CameraFisheye.is_distorted">is_distorted</a></code></li>
<li><code><a title="vcd.scl.CameraFisheye.project_points3d" href="#vcd.scl.CameraFisheye.project_points3d">project_points3d</a></code></li>
<li><code><a title="vcd.scl.CameraFisheye.reproject_points2d" href="#vcd.scl.CameraFisheye.reproject_points2d">reproject_points2d</a></code></li>
<li><code><a title="vcd.scl.CameraFisheye.undistort_image" href="#vcd.scl.CameraFisheye.undistort_image">undistort_image</a></code></li>
<li><code><a title="vcd.scl.CameraFisheye.undistort_points2d" href="#vcd.scl.CameraFisheye.undistort_points2d">undistort_points2d</a></code></li>
<li><code><a title="vcd.scl.CameraFisheye.undistort_rays3d" href="#vcd.scl.CameraFisheye.undistort_rays3d">undistort_rays3d</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="vcd.scl.CameraPinhole" href="#vcd.scl.CameraPinhole">CameraPinhole</a></code></h4>
<ul class="two-column">
<li><code><a title="vcd.scl.CameraPinhole.distort_points2d" href="#vcd.scl.CameraPinhole.distort_points2d">distort_points2d</a></code></li>
<li><code><a title="vcd.scl.CameraPinhole.distort_rays3d" href="#vcd.scl.CameraPinhole.distort_rays3d">distort_rays3d</a></code></li>
<li><code><a title="vcd.scl.CameraPinhole.get_rays3d" href="#vcd.scl.CameraPinhole.get_rays3d">get_rays3d</a></code></li>
<li><code><a title="vcd.scl.CameraPinhole.is_distorted" href="#vcd.scl.CameraPinhole.is_distorted">is_distorted</a></code></li>
<li><code><a title="vcd.scl.CameraPinhole.project_points3d" href="#vcd.scl.CameraPinhole.project_points3d">project_points3d</a></code></li>
<li><code><a title="vcd.scl.CameraPinhole.reproject_points2d" href="#vcd.scl.CameraPinhole.reproject_points2d">reproject_points2d</a></code></li>
<li><code><a title="vcd.scl.CameraPinhole.undistort_image" href="#vcd.scl.CameraPinhole.undistort_image">undistort_image</a></code></li>
<li><code><a title="vcd.scl.CameraPinhole.undistort_points2d" href="#vcd.scl.CameraPinhole.undistort_points2d">undistort_points2d</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="vcd.scl.Edge" href="#vcd.scl.Edge">Edge</a></code></h4>
<ul class="">
<li><code><a title="vcd.scl.Edge.cost" href="#vcd.scl.Edge.cost">cost</a></code></li>
<li><code><a title="vcd.scl.Edge.end" href="#vcd.scl.Edge.end">end</a></code></li>
<li><code><a title="vcd.scl.Edge.start" href="#vcd.scl.Edge.start">start</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="vcd.scl.Graph" href="#vcd.scl.Graph">Graph</a></code></h4>
<ul class="two-column">
<li><code><a title="vcd.scl.Graph.add_edge" href="#vcd.scl.Graph.add_edge">add_edge</a></code></li>
<li><code><a title="vcd.scl.Graph.dijkstra" href="#vcd.scl.Graph.dijkstra">dijkstra</a></code></li>
<li><code><a title="vcd.scl.Graph.get_node_pairs" href="#vcd.scl.Graph.get_node_pairs">get_node_pairs</a></code></li>
<li><code><a title="vcd.scl.Graph.neighbours" href="#vcd.scl.Graph.neighbours">neighbours</a></code></li>
<li><code><a title="vcd.scl.Graph.remove_edge" href="#vcd.scl.Graph.remove_edge">remove_edge</a></code></li>
<li><code><a title="vcd.scl.Graph.vertices" href="#vcd.scl.Graph.vertices">vertices</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="vcd.scl.Scene" href="#vcd.scl.Scene">Scene</a></code></h4>
<ul class="">
<li><code><a title="vcd.scl.Scene.camera_roi_z0" href="#vcd.scl.Scene.camera_roi_z0">camera_roi_z0</a></code></li>
<li><code><a title="vcd.scl.Scene.compute_horizon_line" href="#vcd.scl.Scene.compute_horizon_line">compute_horizon_line</a></code></li>
<li><code><a title="vcd.scl.Scene.get_camera" href="#vcd.scl.Scene.get_camera">get_camera</a></code></li>
<li><code><a title="vcd.scl.Scene.get_transform" href="#vcd.scl.Scene.get_transform">get_transform</a></code></li>
<li><code><a title="vcd.scl.Scene.project_points3d_4xN" href="#vcd.scl.Scene.project_points3d_4xN">project_points3d_4xN</a></code></li>
<li><code><a title="vcd.scl.Scene.reproject_points2d_3xN" href="#vcd.scl.Scene.reproject_points2d_3xN">reproject_points2d_3xN</a></code></li>
<li><code><a title="vcd.scl.Scene.transform_cuboid" href="#vcd.scl.Scene.transform_cuboid">transform_cuboid</a></code></li>
<li><code><a title="vcd.scl.Scene.transform_plane" href="#vcd.scl.Scene.transform_plane">transform_plane</a></code></li>
<li><code><a title="vcd.scl.Scene.transform_points3d_4xN" href="#vcd.scl.Scene.transform_points3d_4xN">transform_points3d_4xN</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="vcd.scl.Sensor" href="#vcd.scl.Sensor">Sensor</a></code></h4>
<ul class="">
<li><code><a title="vcd.scl.Sensor.is_camera" href="#vcd.scl.Sensor.is_camera">is_camera</a></code></li>
<li><code><a title="vcd.scl.Sensor.is_lidar" href="#vcd.scl.Sensor.is_lidar">is_lidar</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>